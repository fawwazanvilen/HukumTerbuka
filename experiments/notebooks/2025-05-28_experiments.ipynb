{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# OpenAI client\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Weave for tracing\n",
    "import weave\n",
    "\n",
    "# MongoDB\n",
    "import pymongo\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "\n",
    "# Pydantic models (reuse your existing models)\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weave Tracing\n",
    "weave.init('HukumTerbuka')\n",
    "\n",
    "# Set up the OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\") or os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document: 11846 characters\n",
      "First 500 characters:\n",
      "PRESIDEN\n",
      "REPUBLIK INDONESIA\n",
      "UNDANG-UNDANG REPUBLIK INDONESIA\n",
      "NOMOR 8 TAHUN 1961\n",
      "TENTANG\n",
      "WAJIB KERJA SARJANA\n",
      "PRESIDEN REPUBLIK INDONESIA,\n",
      "Menimbang:a.bahwa ilmu dan keahlian azasnya untuk mengabdi kepada tanah\n",
      "air, karenanya perlu dikembangkan dan dilaksanakan.\n",
      "b.bahwa  dalam  rangka  pembangunan  nasional  semesta  berencana\n",
      "sangat diperlukan tenaga sarjana dari perbagai jurusan;\n",
      "c.bahwa agar penempatan dan penggunaan tenaga sarjana tersebut\n",
      "teratur  dan  merata  maka  perlu  diadakan  peraturan\n",
      "...\n",
      "\n",
      "Created 7 chunks\n"
     ]
    }
   ],
   "source": [
    "def simple_chunk_text(text: str, chunk_size: int = 2000, overlap: int = 200) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Simple chunking function that splits text every chunk_size characters\n",
    "    with optional overlap to maintain context.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    chunk_id = 1\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk_text = text[start:end]\n",
    "        \n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"chunk_{chunk_id:03d}\",\n",
    "            \"start_pos\": start,\n",
    "            \"end_pos\": min(end, len(text)),\n",
    "            \"content\": chunk_text,\n",
    "            \"char_count\": len(chunk_text)\n",
    "        })\n",
    "        \n",
    "        # Move start position, accounting for overlap\n",
    "        start = end - overlap if end < len(text) else len(text)\n",
    "        chunk_id += 1\n",
    "        \n",
    "        # Safety break to avoid infinite loops\n",
    "        if chunk_id > 100:  # Adjust as needed\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Chunk Sample Doc\n",
    "# Load the sample document\n",
    "sample_doc_path = \"../../raw/UU_8_1961.txt\"\n",
    "\n",
    "try:\n",
    "    with open(sample_doc_path, 'r', encoding='utf-8') as f:\n",
    "        document_text = f.read()\n",
    "    \n",
    "    print(f\"Loaded document: {len(document_text)} characters\")\n",
    "    print(f\"First 500 characters:\")\n",
    "    print(document_text[:500])\n",
    "    print(\"...\")\n",
    "    \n",
    "    # Chunk the document\n",
    "    chunks = simple_chunk_text(document_text, chunk_size=2000, overlap=200)\n",
    "    print(f\"\\nCreated {len(chunks)} chunks\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {sample_doc_path}\")\n",
    "    print(\"Please check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic document structure models\n",
    "class DocumentMeta(BaseModel):\n",
    "    document_type: str  # UU, PP, Perpres, etc.\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class DocumentSection(BaseModel):\n",
    "    tag: str  # pasal, bab, ayat, konsideran, etc.\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['DocumentSection'] = []\n",
    "\n",
    "class LegalDocument(BaseModel):\n",
    "    meta: DocumentMeta\n",
    "    preface: List[DocumentSection] = []\n",
    "    preamble: List[DocumentSection] = []\n",
    "    body: List[DocumentSection] = []\n",
    "    conclusions: List[DocumentSection] = []\n",
    "\n",
    "# Fix the forward reference\n",
    "DocumentSection.model_rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for MongoDB operations\n",
    "class DocumentMetaInput(BaseModel):\n",
    "    document_type: str\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class SectionItem(BaseModel):\n",
    "    tag: str\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['SectionItem'] = Field(default_factory=list)\n",
    "\n",
    "# Fix the forward reference\n",
    "SectionItem.model_rebuild()\n",
    "\n",
    "class ChunkData(BaseModel):\n",
    "    chunk_id: str\n",
    "    start_pos: int\n",
    "    end_pos: int\n",
    "    content: str\n",
    "    char_count: Optional[int] = None\n",
    "\n",
    "class AnalysisResult(BaseModel):\n",
    "    identified_sections: List[SectionItem]\n",
    "    document_meta_found: Optional[DocumentMetaInput] = None\n",
    "    confidence: float\n",
    "    notes: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "# MongoDB connection setup\n",
    "class MongoDBManager:\n",
    "    def __init__(self, connection_string: str = \"mongodb://localhost:27017/\", db_name: str = \"hukum_terbuka\"):\n",
    "        self.connection_string = connection_string\n",
    "        self.db_name = db_name\n",
    "        self.client = None\n",
    "        self.db = None\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Connect to MongoDB\"\"\"\n",
    "        self.client = AsyncIOMotorClient(self.connection_string)\n",
    "        self.db = self.client[self.db_name]\n",
    "        \n",
    "        # Test connection\n",
    "        try:\n",
    "            await self.client.admin.command('ping')\n",
    "            print(f\"✅ Connected to MongoDB: {self.db_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ MongoDB connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def close(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        if self.client:\n",
    "            self.client.close()\n",
    "\n",
    "# Initialize MongoDB manager\n",
    "mongo_manager = MongoDBManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB document schema - matches our Pydantic models but with MongoDB-specific fields\n",
    "class MongoDocument:\n",
    "    \"\"\"\n",
    "    MongoDB document structure for legal documents\n",
    "    \n",
    "    Structure:\n",
    "    {\n",
    "        \"_id\": ObjectId,\n",
    "        \"document_id\": \"unique_doc_id\",\n",
    "        \"meta\": {\n",
    "            \"document_type\": \"UU\",\n",
    "            \"number\": \"8\",\n",
    "            \"year\": \"1961\",\n",
    "            \"title\": \"...\",\n",
    "            \"authority\": \"...\",\n",
    "            \"source_file\": \"...\",\n",
    "            \"created_at\": datetime,\n",
    "            \"updated_at\": datetime\n",
    "        },\n",
    "        \"structure\": {\n",
    "            \"preface\": [...],\n",
    "            \"preamble\": [...],\n",
    "            \"body\": [...],\n",
    "            \"conclusions\": [...]\n",
    "        },\n",
    "        \"processing_status\": {\n",
    "            \"total_chunks\": 10,\n",
    "            \"processed_chunks\": 5,\n",
    "            \"status\": \"processing|completed|failed\",\n",
    "            \"last_updated\": datetime\n",
    "        },\n",
    "        \"chunks\": [\n",
    "            {\n",
    "                \"chunk_id\": \"chunk_001\",\n",
    "                \"start_pos\": 0,\n",
    "                \"end_pos\": 2000,\n",
    "                \"content\": \"...\",\n",
    "                \"analysis\": {...},\n",
    "                \"processed_at\": datetime\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Collection names\n",
    "COLLECTIONS = {\n",
    "    \"documents\": \"legal_documents\",\n",
    "    \"chunks\": \"document_chunks\",\n",
    "    \"processing_logs\": \"processing_logs\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_document_in_db\",\n",
    "            \"description\": \"Create a new legal document in MongoDB\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"document_type\": {\"type\": \"string\"},\n",
    "                            \"number\": {\"type\": \"string\"},\n",
    "                            \"year\": {\"type\": \"string\"},\n",
    "                            \"title\": {\"type\": \"string\"},\n",
    "                            \"authority\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"document_type\"]\n",
    "                    },\n",
    "                    \"source_file\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"meta\", \"source_file\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_document_from_db\",\n",
    "            \"description\": \"Retrieve a legal document from MongoDB\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"document_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_context_for_chunk\",\n",
    "            \"description\": \"Fetch context from previously processed chunks\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"current_chunk_id\": {\"type\": \"string\"},\n",
    "                    \"context_window_size\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"default\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"current_chunk_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"update_document_section\",\n",
    "            \"description\": \"Update a specific section of a legal document (PUT)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"section_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "                    },\n",
    "                    \"section_data\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"tag\": {\"type\": \"string\"},\n",
    "                                \"number\": {\"type\": \"string\"},\n",
    "                                \"title\": {\"type\": \"string\"},\n",
    "                                \"content\": {\"type\": \"string\"},\n",
    "                                \"subsections\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"$ref\": \"#/properties/section_data/items\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"tag\", \"content\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"section_type\", \"section_data\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_document_section\",\n",
    "            \"description\": \"Add a new item to a document section (POST)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"section_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "                    },\n",
    "                    \"section_item\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"tag\": {\"type\": \"string\"},\n",
    "                            \"number\": {\"type\": \"string\"},\n",
    "                            \"title\": {\"type\": \"string\"},\n",
    "                            \"content\": {\"type\": \"string\"},\n",
    "                            \"subsections\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"$ref\": \"#/properties/section_item\"}\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"tag\", \"content\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"section_type\", \"section_item\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"store_chunk_analysis\",\n",
    "            \"description\": \"Store chunk analysis results in the document\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"chunk_data\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"chunk_id\": {\"type\": \"string\"},\n",
    "                            \"start_pos\": {\"type\": \"integer\"},\n",
    "                            \"end_pos\": {\"type\": \"integer\"},\n",
    "                            \"content\": {\"type\": \"string\"},\n",
    "                            \"char_count\": {\"type\": \"integer\"}\n",
    "                        },\n",
    "                        \"required\": [\"chunk_id\", \"start_pos\", \"end_pos\", \"content\"]\n",
    "                    },\n",
    "                    \"analysis\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"identified_sections\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"tag\": {\"type\": \"string\"},\n",
    "                                        \"number\": {\"type\": \"string\"},\n",
    "                                        \"title\": {\"type\": \"string\"},\n",
    "                                        \"content\": {\"type\": \"string\"},\n",
    "                                        \"subsections\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"items\": {\"$ref\": \"#/properties/analysis/properties/identified_sections/items\"}\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"tag\", \"content\"]\n",
    "                                }\n",
    "                            },\n",
    "                            \"document_meta_found\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"document_type\": {\"type\": \"string\"},\n",
    "                                    \"number\": {\"type\": \"string\"},\n",
    "                                    \"year\": {\"type\": \"string\"},\n",
    "                                    \"title\": {\"type\": \"string\"},\n",
    "                                    \"authority\": {\"type\": \"string\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"confidence\": {\"type\": \"number\"},\n",
    "                            \"notes\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"identified_sections\", \"confidence\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"chunk_data\", \"analysis\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"update_processing_status\",\n",
    "            \"description\": \"Update document processing status\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\"},\n",
    "                    \"status\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"created\", \"processing\", \"completed\", \"failed\"]\n",
    "                    },\n",
    "                    \"total_chunks\": {\"type\": \"integer\"}\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"status\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "TOOL_MAPPING = {\n",
    "    \"create_document_in_db\": create_document_in_db,\n",
    "    \"get_document_from_db\": get_document_from_db,\n",
    "    \"get_context_for_chunk\": get_context_for_chunk,\n",
    "    \"update_document_section\": update_document_section,\n",
    "    \"add_document_section\": add_document_section,\n",
    "    \"store_chunk_analysis\": store_chunk_analysis,\n",
    "    \"update_processing_status\": update_processing_status\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function tools with proper Pydantic models\n",
    "async def create_document_in_db(document_id: str, meta: dict, source_file: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a new legal document in MongoDB\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        meta: Document metadata (type, number, year, title, authority)\n",
    "        source_file: Path to source file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert dict to Pydantic model\n",
    "        meta_model = DocumentMetaInput(**meta)\n",
    "        meta_dict = meta_model.model_dump()\n",
    "        \n",
    "        document = {\n",
    "            \"document_id\": document_id,\n",
    "            \"meta\": {\n",
    "                **meta_dict,\n",
    "                \"source_file\": source_file,\n",
    "                \"created_at\": datetime.datetime.now(datetime.UTC),\n",
    "                \"updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "            },\n",
    "            \"structure\": {\n",
    "                \"preface\": [],\n",
    "                \"preamble\": [],\n",
    "                \"body\": [],\n",
    "                \"conclusions\": []\n",
    "            },\n",
    "            \"processing_status\": {\n",
    "                \"total_chunks\": 0,\n",
    "                \"processed_chunks\": 0,\n",
    "                \"status\": \"created\",\n",
    "                \"last_updated\": datetime.datetime.now(datetime.UTC)\n",
    "            },\n",
    "            \"chunks\": []\n",
    "        }\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].insert_one(document)\n",
    "        return f\"Document created with ID: {result.inserted_id}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error creating document: {str(e)}\"\n",
    "\n",
    "async def get_document_from_db(document_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve a legal document from MongoDB\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document = await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": document_id}\n",
    "        )\n",
    "        \n",
    "        if document:\n",
    "            # Convert ObjectId to string for JSON serialization\n",
    "            document[\"_id\"] = str(document[\"_id\"])\n",
    "            return json.dumps(document, default=str, ensure_ascii=False, indent=2)\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving document: {str(e)}\"\n",
    "\n",
    "async def update_document_section(document_id: str, section_type: str, section_data: list) -> str:\n",
    "    \"\"\"\n",
    "    Update a specific section of a legal document (PUT operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        section_type: Type of section (preface, preamble, body, conclusions)\n",
    "        section_data: Section data to update\n",
    "    \"\"\"\n",
    "    try:\n",
    "        valid_sections = [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "        if section_type not in valid_sections:\n",
    "            return f\"Invalid section type. Must be one of: {valid_sections}\"\n",
    "        \n",
    "        # Convert list of dicts to Pydantic models\n",
    "        section_models = [SectionItem(**item) for item in section_data]\n",
    "        section_data_dict = [item.model_dump() for item in section_models]\n",
    "        \n",
    "        update_data = {\n",
    "            f\"structure.{section_type}\": section_data_dict,\n",
    "            \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\"$set\": update_data}\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Updated {section_type} section for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error updating document section: {str(e)}\"\n",
    "\n",
    "async def add_document_section(document_id: str, section_type: str, section_item: dict) -> str:\n",
    "    \"\"\"\n",
    "    Add a new item to a document section (POST operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        section_type: Type of section (preface, preamble, body, conclusions)\n",
    "        section_item: New section item to add\n",
    "    \"\"\"\n",
    "    try:\n",
    "        valid_sections = [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "        if section_type not in valid_sections:\n",
    "            return f\"Invalid section type. Must be one of: {valid_sections}\"\n",
    "        \n",
    "        # Convert dict to Pydantic model\n",
    "        section_item_model = SectionItem(**section_item)\n",
    "        section_item_dict = section_item_model.model_dump()\n",
    "        \n",
    "        update_data = {\n",
    "            f\"structure.{section_type}\": section_item_dict,\n",
    "            \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\"$push\": update_data}\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Added new item to {section_type} section for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error adding to document section: {str(e)}\"\n",
    "\n",
    "async def store_chunk_analysis(document_id: str, chunk_data: dict, analysis: dict) -> str:\n",
    "    \"\"\"\n",
    "    Store chunk analysis results in the document (PATCH operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        chunk_data: Chunk information (chunk_id, start_pos, end_pos, content)\n",
    "        analysis: Analysis results from the agent\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert dicts to Pydantic models\n",
    "        chunk_data_model = ChunkData(**chunk_data)\n",
    "        analysis_model = AnalysisResult(**analysis)\n",
    "        \n",
    "        # Convert Pydantic models to dicts\n",
    "        chunk_data_dict = chunk_data_model.model_dump()\n",
    "        analysis_dict = analysis_model.model_dump()\n",
    "        \n",
    "        chunk_with_analysis = {\n",
    "            **chunk_data_dict,\n",
    "            \"analysis\": analysis_dict,\n",
    "            \"processed_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        # Add chunk to document\n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\n",
    "                \"$push\": {\"chunks\": chunk_with_analysis},\n",
    "                \"$inc\": {\"processing_status.processed_chunks\": 1},\n",
    "                \"$set\": {\n",
    "                    \"processing_status.last_updated\": datetime.datetime.now(datetime.UTC),\n",
    "                    \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Stored analysis for chunk {chunk_data_model.chunk_id} in document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error storing chunk analysis: {str(e)}\"\n",
    "\n",
    "async def update_processing_status(document_id: str, status: str, total_chunks: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Update document processing status\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        status: New status (created, processing, completed, failed)\n",
    "        total_chunks: Total number of chunks (optional)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        update_data = {\n",
    "            \"processing_status.status\": status,\n",
    "            \"processing_status.last_updated\": datetime.datetime.datetime.now(datetime.UTC),\n",
    "            \"meta.updated_at\": datetime.datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        if total_chunks is not None:\n",
    "            update_data[\"processing_status.total_chunks\"] = total_chunks\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\"$set\": update_data}\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Updated processing status to '{status}' for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error updating processing status: {str(e)}\"\n",
    "    \n",
    "async def get_context_for_chunk(document_id: str, current_chunk_id: str, context_window_size: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Fetch context from previously processed chunks\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        current_chunk_id: ID of the current chunk being processed\n",
    "        context_window_size: Number of previous chunks to include in context\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the document\n",
    "        document = await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": document_id}\n",
    "        )\n",
    "        \n",
    "        if not document:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "        \n",
    "        # Extract current chunk number\n",
    "        try:\n",
    "            current_chunk_num = int(current_chunk_id.split('_')[-1])\n",
    "        except:\n",
    "            return \"Invalid chunk ID format\"\n",
    "        \n",
    "        # Find previous chunks\n",
    "        previous_chunks = []\n",
    "        for chunk in document.get(\"chunks\", []):\n",
    "            try:\n",
    "                chunk_num = int(chunk[\"chunk_id\"].split('_')[-1])\n",
    "                if chunk_num < current_chunk_num and chunk_num >= current_chunk_num - context_window_size:\n",
    "                    previous_chunks.append(chunk)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Sort by chunk number\n",
    "        previous_chunks.sort(key=lambda x: int(x[\"chunk_id\"].split('_')[-1]))\n",
    "        \n",
    "        # Format context information\n",
    "        context = {\n",
    "            \"previous_chunks\": previous_chunks,\n",
    "            \"document_structure\": document.get(\"structure\", {}),\n",
    "            \"metadata\": document.get(\"meta\", {})\n",
    "        }\n",
    "        \n",
    "        return json.dumps(context, default=str, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error fetching context: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic document structure models\n",
    "class DocumentMeta(BaseModel):\n",
    "    document_type: str  # UU, PP, Perpres, etc.\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class DocumentSection(BaseModel):\n",
    "    tag: str  # pasal, bab, ayat, konsideran, etc.\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['DocumentSection'] = []\n",
    "\n",
    "class LegalDocument(BaseModel):\n",
    "    meta: DocumentMeta\n",
    "    preface: List[DocumentSection] = []\n",
    "    preamble: List[DocumentSection] = []oroe \n",
    "    body: List[DocumentSection] = []\n",
    "    conclusions: List[DocumentSection] = []\n",
    "\n",
    "# Fix the forward reference\n",
    "DocumentSection.model_rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for MongoDB operations\n",
    "class DocumentMetaInput(BaseModel):\n",
    "    document_type: str\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class SectionItem(BaseModel):\n",
    "    tag: str\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['SectionItem'] = Field(default_factory=list)\n",
    "\n",
    "# Fix the forward reference\n",
    "SectionItem.model_rebuild()\n",
    "\n",
    "class ChunkData(BaseModel):\n",
    "    chunk_id: str\n",
    "    start_pos: int\n",
    "    end_pos: int\n",
    "    content: str\n",
    "    char_count: Optional[int] = None\n",
    "\n",
    "class AnalysisResult(BaseModel):\n",
    "    identified_sections: List[SectionItem]\n",
    "    document_meta_found: Optional[DocumentMetaInput] = None\n",
    "    confidence: float\n",
    "    notes: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkAnalysis(BaseModel):\n",
    "    chunk_id: str\n",
    "    identified_sections: List[DocumentSection]\n",
    "    document_meta_found: Optional[DocumentMeta] = None\n",
    "    confidence: float  # 0.0 to 1.0\n",
    "    notes: str = \"\"\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"ChunkAnalysis\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": AnalysisResult.model_json_schema()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agentic_loop(system_prompt: str, prompt: str, tools, tool_mapping, response_format=None):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        response = await client.chat.completions.create(\n",
    "            # model=\"openai/gpt-4.1-mini\",\n",
    "            model=\"google/gemini-2.5-flash-preview-05-20\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            response_format=response_format\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message\n",
    "        # messages.append(message.dict()) # deprecated\n",
    "        messages.append(message.model_dump())\n",
    "\n",
    "        if message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "                tool_result = await tool_mapping[tool_name](**tool_args)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": json.dumps(tool_result)\n",
    "                })\n",
    "        else:\n",
    "            return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available legal document tags/elements\n",
    "AVAILABLE_TAGS = {\n",
    "    \"structural\": [\"bab\", \"bagian\", \"paragraf\", \"pasal\", \"ayat\"],\n",
    "    \"preamble\": [\"konsideran_menimbang\", \"konsideran_mengingat\", \"memutuskan\"],\n",
    "    \"content\": [\"definisi\", \"ketentuan_umum\", \"ketentuan_khusus\", \"sanksi\", \"ketentuan_peralihan\", \"ketentuan_penutup\"],\n",
    "    \"meta\": [\"judul\", \"nomor\", \"tahun\", \"tentang\", \"pembentuk\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the document analysis agent\n",
    "system_prompt=f\"\"\"\n",
    "You are an expert in Indonesian legal documents with access to a MongoDB database.\n",
    "Your task is to analyze chunks of legal text with awareness of previously processed chunks.\n",
    "\n",
    "Available tags you can use:\n",
    "{json.dumps(AVAILABLE_TAGS, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Your workflow:\n",
    "1. Decide if you need context from previous chunks\n",
    "2. If needed, fetch context using get_context_for_chunk\n",
    "3. Analyze the current chunk with awareness of this context\n",
    "4. Store your analysis and update the document structure\n",
    "5. Consider how this chunk connects to previous chunks\n",
    "\n",
    "When analyzing with context:\n",
    "- Look for sections that span across chunk boundaries\n",
    "- Avoid duplicating sections already identified in previous chunks\n",
    "- Connect partial sections across chunks (e.g., if a pasal starts in one chunk and continues in another)\n",
    "- Use document structure information to maintain consistency\n",
    "\n",
    "Available MongoDB tools:\n",
    "- create_document_in_db: Create a new document\n",
    "- get_document_from_db: Retrieve existing document\n",
    "- get_context_for_chunk: Fetch context from previous chunks\n",
    "- update_document_section: Update entire sections (PUT)\n",
    "- add_document_section: Add items to sections (POST)\n",
    "- store_chunk_analysis: Store chunk analysis results\n",
    "- update_processing_status: Update processing status\n",
    "\n",
    "Rules:\n",
    "- Always consider context before making decisions\n",
    "- Be conservative when deciding what's a new section vs. continuation\n",
    "- Store your analysis even if you're uncertain\n",
    "- Add notes about cross-chunk connections\n",
    "\n",
    "Tips:\n",
    "- You should check if the db exists and if the document is already in the db\n",
    "- If the document is not in the db, create it with the initial metadata\n",
    "- Use the get_context_for_chunk tool to fetch context from previous chunks\n",
    "- Use the store_chunk_analysis tool to save your analysis results\n",
    "- Use the update_document_section tool to update sections\n",
    "- Use the add_document_section tool to add new items to sections\n",
    "- Use the update_processing_status tool to update the processing status of the document\n",
    "- If you need to create a new document, use the create_document_in_db tool \n",
    "- If you need to retrieve a document, use the get_document_from_db tool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing chunk: chunk_001\n",
      "Content preview: PRESIDEN\n",
      "REPUBLIK INDONESIA\n",
      "UNDANG-UNDANG REPUBLIK INDONESIA\n",
      "NOMOR 8 TAHUN 1961\n",
      "TENTANG\n",
      "WAJIB KERJA SARJANA\n",
      "PRESIDEN REPUBLIK INDONESIA,\n",
      "Menimbang:a.bahwa ilmu dan keahlian azasnya untuk mengabdi kepa...\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if 'chunks' in locals() and len(chunks) > 0:\n",
    "    first_chunk = chunks[0]\n",
    "    \n",
    "    print(f\"Analyzing chunk: {first_chunk['chunk_id']}\")\n",
    "    print(f\"Content preview: {first_chunk['content'][:200]}...\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    prompt = f\"Analyze this chunk of Indonesian legal document text:\\n\\nChunk ID: {first_chunk['chunk_id']}\\n\\nContent:\\n{first_chunk['content']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_json = await run_agentic_loop(prompt, tools, TOOL_MAPPING, response_format)\n",
    "# analysis = AnalysisResult.model_validate_json(result_json)\n",
    "\n",
    "result_json = await run_agentic_loop(system_prompt, prompt, tools, TOOL_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The tools are consistently returning errors. It seems there's a persistent issue preventing the storage and update of document sections. I am unable to proceed with the chunk analysis as I cannot store the results of my analysis. I recommend checking the MongoDB database connection and the functions' implementations to resolve these recurring errors (`model_dump` attribute missing, datetime object errors).\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coretan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB: hukum_terbuka\n",
      "Testing with document ID: test_doc_d744cc54\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:62\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n\u001b[32m     58\u001b[39m     model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n\u001b[32m     59\u001b[39m     model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n\u001b[32m     60\u001b[39m     disabled=tracing.is_disabled(),\n\u001b[32m     61\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     63\u001b[39m         system_instructions,\n\u001b[32m     64\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     65\u001b[39m         model_settings,\n\u001b[32m     66\u001b[39m         tools,\n\u001b[32m     67\u001b[39m         output_schema,\n\u001b[32m     68\u001b[39m         handoffs,\n\u001b[32m     69\u001b[39m         span_generation,\n\u001b[32m     70\u001b[39m         tracing,\n\u001b[32m     71\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     72\u001b[39m     )\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:252\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, span, tracing, stream)\u001b[39m\n\u001b[32m    248\u001b[39m stream_options = ChatCmplHelpers.get_stream_options_param(\n\u001b[32m    249\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_client(), model_settings, stream=stream\n\u001b[32m    250\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_client().chat.completions.create(\n\u001b[32m    253\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    254\u001b[39m     messages=converted_messages,\n\u001b[32m    255\u001b[39m     tools=converted_tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    256\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    257\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    258\u001b[39m     frequency_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.frequency_penalty),\n\u001b[32m    259\u001b[39m     presence_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.presence_penalty),\n\u001b[32m    260\u001b[39m     max_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    261\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    262\u001b[39m     response_format=response_format,\n\u001b[32m    263\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    264\u001b[39m     stream=stream,\n\u001b[32m    265\u001b[39m     stream_options=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(stream_options),\n\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(store),\n\u001b[32m    267\u001b[39m     reasoning_effort=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(reasoning_effort),\n\u001b[32m    268\u001b[39m     extra_headers={**HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    269\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    270\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    271\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    272\u001b[39m )\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, ChatCompletion):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/trace/op.py:1224\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1222\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:  \u001b[38;5;66;03m# pyright: ignore[reportRedeclaration]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m     res, _ = \u001b[38;5;28;01mawait\u001b[39;00m _call_async_func(\n\u001b[32m   1225\u001b[39m         cast(Op[P, R], wrapper), *args, __should_raise=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs\n\u001b[32m   1226\u001b[39m     )\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/trace/op.py:636\u001b[39m, in \u001b[36m_call_async_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai/openai_sdk.py:366\u001b[39m, in \u001b[36mcreate_wrapper_async.<locals>.wrapper.<locals>._add_stream_options.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/resources/chat/completions/completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2027\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2029\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2030\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2031\u001b[39m         {\n\u001b[32m   2032\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2033\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2034\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2035\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2036\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2037\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2038\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2039\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2040\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2041\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2042\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2043\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2044\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2045\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2046\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2047\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2048\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2049\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2050\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2051\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2052\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2053\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2054\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2055\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2056\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2058\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2059\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2060\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2061\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2062\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2063\u001b[39m         },\n\u001b[32m   2064\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2065\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2066\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2067\u001b[39m     ),\n\u001b[32m   2068\u001b[39m     options=make_request_options(\n\u001b[32m   2069\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2070\u001b[39m     ),\n\u001b[32m   2071\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2072\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2073\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2074\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1739\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/_base_client.py:1484\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1485\u001b[39m         request,\n\u001b[32m   1486\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1487\u001b[39m         **kwargs,\n\u001b[32m   1488\u001b[39m     )\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/streams/tls.py:219\u001b[39m, in \u001b[36mTLSStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m = \u001b[32m65536\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_sslobject_method(\u001b[38;5;28mself\u001b[39m._ssl_object.read, max_bytes)\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/streams/tls.py:162\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/_backends/_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting with document ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_doc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Test document creation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m     14\u001b[39m     document_analyzer,\n\u001b[32m     15\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m    Create a new document in the database with the following information:\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m    - Document ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_doc_id\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33m    - Document Type: UU\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m    - Number: 8\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m    - Year: 1961\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m    - Title: Undang-Undang tentang Wajib Kerja\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m    - Authority: Presiden Republik Indonesia\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m    - Source File: raw/UU_8_1961.txt\u001b[39m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[33m    Then retrieve the document to confirm it was created.\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m    (retrieve just with the document ID str, don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt include the dic, eg just \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_doc_eb9acd2b\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDocument creation test result:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.final_output.model_dump_json(indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:218\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    213\u001b[39m logger.debug(\n\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m )\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m    221\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    222\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    223\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    224\u001b[39m             context_wrapper,\n\u001b[32m    225\u001b[39m         ),\n\u001b[32m    226\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    227\u001b[39m             agent=current_agent,\n\u001b[32m    228\u001b[39m             all_tools=all_tools,\n\u001b[32m    229\u001b[39m             original_input=original_input,\n\u001b[32m    230\u001b[39m             generated_items=generated_items,\n\u001b[32m    231\u001b[39m             hooks=hooks,\n\u001b[32m    232\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    233\u001b[39m             run_config=run_config,\n\u001b[32m    234\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    235\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    236\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:762\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    760\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    763\u001b[39m     agent,\n\u001b[32m    764\u001b[39m     system_prompt,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    766\u001b[39m     output_schema,\n\u001b[32m    767\u001b[39m     all_tools,\n\u001b[32m    768\u001b[39m     handoffs,\n\u001b[32m    769\u001b[39m     context_wrapper,\n\u001b[32m    770\u001b[39m     run_config,\n\u001b[32m    771\u001b[39m     tool_use_tracker,\n\u001b[32m    772\u001b[39m     previous_response_id,\n\u001b[32m    773\u001b[39m )\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    776\u001b[39m     agent=agent,\n\u001b[32m    777\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    787\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:921\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    918\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    919\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    922\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    923\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    924\u001b[39m     model_settings=model_settings,\n\u001b[32m    925\u001b[39m     tools=all_tools,\n\u001b[32m    926\u001b[39m     output_schema=output_schema,\n\u001b[32m    927\u001b[39m     handoffs=handoffs,\n\u001b[32m    928\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    929\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    930\u001b[39m     ),\n\u001b[32m    931\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    932\u001b[39m )\n\u001b[32m    934\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:57\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     48\u001b[39m     system_instructions: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     previous_response_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     56\u001b[39m ) -> ModelResponse:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n\u001b[32m     58\u001b[39m         model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n\u001b[32m     59\u001b[39m         model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n\u001b[32m     60\u001b[39m         disabled=tracing.is_disabled(),\n\u001b[32m     61\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n\u001b[32m     62\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     63\u001b[39m             system_instructions,\n\u001b[32m     64\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     72\u001b[39m         )\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/spans.py:237\u001b[39m, in \u001b[36mSpanImpl.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    234\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mGeneratorExit, skipping span reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    235\u001b[39m     reset_current = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreset_current\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_current\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/spans.py:222\u001b[39m, in \u001b[36mSpanImpl.finish\u001b[39m\u001b[34m(self, reset_current)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m._ended_at = util.time_iso()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_span_end\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_current \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prev_span_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    224\u001b[39m     Scope.reset_current_span(\u001b[38;5;28mself\u001b[39m._prev_span_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/setup.py:65\u001b[39m, in \u001b[36mSynchronousMultiTracingProcessor.on_span_end\u001b[39m\u001b[34m(self, span)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03mCalled when a span is finished.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._processors:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_span_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:363\u001b[39m, in \u001b[36mWeaveTracingProcessor.on_span_end\u001b[39m\u001b[34m(self, span)\u001b[39m\n\u001b[32m    361\u001b[39m span_name = _call_name(span)\n\u001b[32m    362\u001b[39m span_type = _call_type(span)\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m log_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# For Response spans, create the call here so we can include input data\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    367\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.ResponseSpanData)\n\u001b[32m    368\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m span.span_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._span_calls\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;66;03m# Create attributes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:289\u001b[39m, in \u001b[36mWeaveTracingProcessor._log_data\u001b[39m\u001b[34m(self, span)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail_log_data(span)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.GenerationSpanData):\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generation_log_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.CustomSpanData):\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._custom_log_data(span)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:230\u001b[39m, in \u001b[36mWeaveTracingProcessor._generation_log_data\u001b[39m\u001b[34m(self, span)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generation_log_data\u001b[39m(\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m, span: tracing.Span[tracing.GenerationSpanData]\n\u001b[32m    220\u001b[39m ) -> WeaveDataDict:\n\u001b[32m    221\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Extract log data from a generation span.\"\"\"\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WeaveDataDict(\n\u001b[32m    223\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.input},\n\u001b[32m    224\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.output},\n\u001b[32m    225\u001b[39m         metadata={\n\u001b[32m    226\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.model,\n\u001b[32m    227\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.model_config,\n\u001b[32m    228\u001b[39m         },\n\u001b[32m    229\u001b[39m         metrics={\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mspan\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspan_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43musage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mtotal_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_tokens\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.usage.get(\u001b[33m\"\u001b[39m\u001b[33mprompt_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    232\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcompletion_tokens\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.usage.get(\u001b[33m\"\u001b[39m\u001b[33mcompletion_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    233\u001b[39m         },\n\u001b[32m    234\u001b[39m         error=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    235\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Test MongoDB integration\n",
    "# Connect to MongoDB\n",
    "connected = await mongo_manager.connect()\n",
    "if not connected:\n",
    "    print(\"Failed to connect to MongoDB. Please ensure MongoDB is running.\")\n",
    "\n",
    "# Generate a test document ID\n",
    "test_doc_id = f\"test_doc_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "print(f\"Testing with document ID: {test_doc_id}\")\n",
    "\n",
    "# Test document creation\n",
    "result = await Runner.run(\n",
    "    document_analyzer,\n",
    "    f\"\"\"\n",
    "    Create a new document in the database with the following information:\n",
    "    - Document ID: {test_doc_id}\n",
    "    - Document Type: UU\n",
    "    - Number: 8\n",
    "    - Year: 1961\n",
    "    - Title: Undang-Undang tentang Wajib Kerja\n",
    "    - Authority: Presiden Republik Indonesia\n",
    "    - Source File: raw/UU_8_1961.txt\n",
    "    \n",
    "    Then retrieve the document to confirm it was created.\n",
    "    (retrieve just with the document ID str, don't include the dic, eg just \"test_doc_eb9acd2b\")\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Document creation test result:\")\n",
    "print(result.final_output.model_dump_json(indent=2))\n",
    "print(result.raw_responses)\n",
    "\n",
    "print(test_doc_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB: hukum_terbuka\n",
      "Loaded document: 11846 characters\n",
      "Processing document with ID: doc_e2385b78\n",
      "Created 7 chunks\n",
      "\n",
      "Processing chunk 1/7: chunk_001\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_jube0h98LlCaDOeQhIUl95rD', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2431, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2453), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Presiden Republik Indonesia\"},\"source_file\":\"\"}', call_id='call_sRetWkhDHunXZDaeB0pVZMym', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2473, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=67, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2540), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Presiden Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_2tHqFISZQlQDEaY5QMX2xzAI', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2566, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=67, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2633), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Presiden Republik Indonesia\"},\"source_file\":\"-\"}', call_id='call_i6VzLlVXWH0L1FvpVLAZnoc4', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2659, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=67, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2726), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Presiden Republik Indonesia\"},\"source_file\":\"doc_e2385b78\"}', call_id='call_p9cr0VSsXELaI8PKkGXzaraf', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2752, input_tokens_details=InputTokensDetails(cached_tokens=2688), output_tokens=72, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2824), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_001\",\"identified_sections\":[{\"tag\":\"meta.judul\",\"number\":null,\"title\":null,\"content\":\"UNDANG-UNDANG REPUBLIK INDONESIA NOMOR 8 TAHUN 1961 TENTANG WAJIB KERJA SARJANA\",\"subsections\":[]},{\"tag\":\"preamble.konsideran_menimbang\",\"number\":null,\"title\":null,\"content\":\"a. bahwa ilmu dan keahlian azasnya untuk mengabdi kepada tanah air, karenanya perlu dikembangkan dan dilaksanakan.\\\\nb. bahwa dalam rangka pembangunan nasional semesta berencana sangat diperlukan tenaga sarjana dari perbagai jurusan;\\\\nc. bahwa agar penempatan dan penggunaan tenaga sarjana tersebut teratur dan merata maka perlu diadakan peraturan wajib kerja sarjana;\",\"subsections\":[]},{\"tag\":\"preamble.konsideran_mengingat\",\"number\":null,\"title\":null,\"content\":\"a. Pasal 5 ayat (1) jo. pasal 20 ayat (1) dan pasal 27 ayat (2) Undang-undang Dasar;\\\\nb. Ketetapan Majelis Permusyawaratan Rakyat Sementara Nomor 1 /MPRS/1960 dan Nomor II/MPRS/1960;\\\\nc. Undang-undang Nomor 10 Prp. tahun 1960 (Lembaran-Negara tahun 1960 Nomor 31);\",\"subsections\":[]},{\"tag\":\"preamble.memutuskan\",\"number\":null,\"title\":null,\"content\":\"I. Mencabut:Undang-undang Nomor 8 tahun 1951 tentang penangguhan pemberian izin kepada dokter dan dokter gigi dan segala peraturanyangbertentangandenganUndang-undangini (Lembaran-Negara tahun 1951 Nomor 44);\\\\nII. Menetapkan:UNDANG-UNDANG TENTANG WAJIB KERJA SARJANA.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"1\",\"title\":null,\"content\":\"(1) Tiap warganegara, baik pria maupun wanita,\\\\na. yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi Negara;\\\\nb. yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi Swasta, yang ditunjuk oleh Menteri yang diserahi urusan Perguruan tinggi,\\\\nc. yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi diluar negeri, yang ditunjuk oleh Menteri yang diserahi urusan perguruan tinggi.\\\\nSemuanya itu disebut sarjana, wajib bekerja pada Pemerintah atau pada perusahaan-perusahaan yang ditunjuk oleh Pemerintah sekurang-kurangnya selama tiga tahun berturut-turut .\\\\n(2) Dalam peraturan ini Akademi dikecualikan dari istilah Perguruan Tinggi.\\\\n(3) Bagi pendidikan tinggi Kedokteran, Kedokteran gigi, KedokteranHewan, Apoteker dan Akuntan ijazah ujian penghab...\",\"subsections\":[]}],\"document_meta_found\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Presiden Republik Indonesia\"},\"confidence\":0.95,\"notes\":\"Document meta and multiple preamble sections identified from the header and structure. Pasal 1 is only partially present and likely continues into the next chunk.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2850, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=745, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3595), response_id=None)]\n",
      "Chunk chunk_001 processed with confidence: 0.95\n",
      "Sections found: 5\n",
      "\n",
      "Processing chunk 2/7: chunk_002\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_onmp4Bs0rQ3hlmGhg9EtM1H1', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2380, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2402), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_GJp7p0MIGgHvVqm287KUWGQV', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2422, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2472), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_7fxp4wka8fdDjJAJRWXHIoNh', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2498, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2548), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Peraturan Pemerintah (dugaan)\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_HvGSrz1Ml7RtUBkk975Y2uUH', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2574, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=57, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2631), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_002\",\"identified_sections\":[{\"tag\":\"pasal\",\"number\":\"1\",\"title\":null,\"content\":\"lam peraturan ini Akademi dikecualikan dari istilah Perguruan Tinggi.\\\\n(3)Bagi   pendidikan   tinggi   Kedokteran,   Kedokteran   gigi,   KedokteranHewan, Apoteker  dan  Akuntan  ijazah  ujian  penghabisan  yang  termaksud  pada  ayat  (1) ialah ijazah setelah lulus menempuh berturut-turut ujian-ujian dokter, dokter gigi, dokter hewan, apoteker dan akuntan.\\\\n(4)Sarjana yang telah lulus dalam ujian penghabisantersebut dalam ayat (1) dan ayat (3)  pasal  ini  yang  sedang  mempersiapkan  thesis  untuk  memperoleh  gelar  ilmiah \\\\\"Doktor\\\\\" sementara dibebaskan dari wajib kerja, bila ada keterangan dari Presiden Universitas atau Pemimpin Sekolah Tinggi termaksud dalam pasal 5ayat (1); wajib kerja bagi mereka ini mulai berlaku setelah mereka mencapai gelar \\\\\"Doktor\\\\\".\\\\n(5)Seorang sarjana yang telah berusia 50 tahun dapat dibebaskan dari kewajiban ini.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"2\",\"title\":null,\"content\":\"Departemen   yang   diserahi   urusan   perguruan   tinggi   mengadakan   daftar   sarjana termaksud dalam pasal 1.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"3\",\"title\":null,\"content\":\"(1)Untuk Penempatan sarjana termaksud pada pasal 1 dibentuk Dewan Penempatan Sarjana   yang   berkedudukan   langsung   dibawah   dan   diketuai   oleh   Menteri Perburuhan.\\\\n(2)Dewan  Penempatan   Sarjana  tersebut  anggotanya,  selain  Menteri  Perburuhan, terdiri atas wakil-wakil yang diberi kuasa penuh dari Menteri-Menteri:\\\\na.Pendidikan, Pengetahuan dan Kebudayaan,\\\\nb.Perguruan Tinggi dan Ilmu Pengetahuan,\\\\nc.Keamanan Nasional,\\\\nd.Pembangunan,\\\\ne.Produksi,\\\\nf.Distribusi,\\\\ng.Kesehatan,\\\\nh.Agama.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"4\",\"title\":null,\"content\":\"Wewenang  ,  Tugas-kewajiban  dan  susunan  Dewan  Penempatan  Sarjana  ditetapkan dalam Peraturan Pemerintah.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"5\",\"title\":null,\"content\":\"(1)Presiden Universitas negara, Pemimpin sekolah tinggi negara, Presiden universitas swasta  serta  Pemimpin  sekolah  tinggi  swasta  yang  ditunjuk  oleh  Menteri  yang diserahi  urusan  perguruan  tinggi,  wajib  memberitahukan  kepada  Departemen yang diserahi urusan perguruan tinggi tentang lulusnya seorang mahasiswa dalam waktu sebulan sesudah memperoleh ijazah ujian penghabisan.\",\"subsections\":[]}],\"document_meta_found\":{\"document_type\":\"Peraturan Pemerintah (dugaan)\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"confidence\":0.85,\"notes\":\"Identified pasal 1 (lanjutan, mulai dari ayat 3), pasal 2, pasal 3, pasal 4, dan pasal 5. This is not the first chunk; section tagging assumes pasal 1 started previously (earlier chunk likely has initial ayat of pasal 1). Meta is speculative due to limited info. Error occurred in MongoDB document creation; no sections updated in DB. Connect with previous chunk to corroborate structure.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2657, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=839, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3496), response_id=None)]\n",
      "Chunk chunk_002 processed with confidence: 0.85\n",
      "Sections found: 5\n",
      "\n",
      "Processing chunk 3/7: chunk_003\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_DmqIMNKMuuveikHS027OzYm3', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2356, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2378), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_CPtozzJ9UFbdR65ieTNMevfO', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2398, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2448), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_N9NjvUPWEJpiiZIQnueWoH85', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2474, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2524), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"peraturan\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_828VpACVHp6yPQHYkvOQS5lh', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2550, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=51, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2601), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"current_chunk_id\":\"chunk_003\",\"context_window_size\":2}', call_id='call_SWpIlSR5OVT3MXe9H5ez0mKs', name='get_context_for_chunk', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2627, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2663), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_003\",\"identified_sections\":[{\"tag\":\"pasal\",\"number\":\"5\",\"title\":null,\"content\":\"(1) perguruan tinggi, wajib memberitahukan kepada Departemen yang diserahi urusan perguruan tinggi tentang lulusnya seorang mahasiswa dalam waktu sebulan sesudah memperoleh ijazah ujian penghabisan.\\\\n(2) Lulusan termaksud dalam pasal 1 ayat (1) huruf a dan b dalam waktu sebulan memperoleh ijazah ujian penghabisan dan lulusan termaksud dalam pasal 1 ayat (1) huruf c dalam waktu sebulan setibanya di Indonesia, wajib menyampaikan secara tertulis kepada Departemen yang diserahi urusan perguruan tinggi keterangan-keterangan yang dimaksudkan pada ayat (1) pasal ini, disertai penjelasan yang dianggapnya perlu, agar penempatan mereka mungkin dilakukan sesuai dengan bakat dan kehendak masing-masing.\\\\n(3) Bila mereka sedang mempersiapkan thesis untuk mencapai gelar ilmiah \\\\\"Doktor\\\\\" maka keterangan itu harus disertai dengan surat keterangan dari Presiden Universitas atau pemimpin Sekolah Tinggi sebagai termaksud dalam pasal 1 ayat (4).\\\\n(4) Ketentuan yang bertalian dengan pendaftaran termaksud dalam ayat (1) dan (2) ditetapkan dalam Peratuaran Pemerintah.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"6\",\"title\":null,\"content\":\"Semua Departemen dan instansi-instansi lain yang tidak termasuk dalam lingkungan sesuatu Departemen, pada waktu tertentu memberitahukan kepada Departemen yang diserahi urusan perguruan tinggi dan Dewan Penempatan Sarjana, banyaknya sarjana yang bekerja padanya. Pada tiap permulaan tahun takwin diberitahukan pula banyaknya sarjana yang dibutuhkan dibubuhi keterangan-keterangan yang perlu.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"7\",\"title\":null,\"content\":\"(1) Pelanggaran pasal 5 ayat (2) dipidana dengan pidana selama-lamanya enam bulan atau didenda sebanyak-banyaknya sepuluh ribu rupiah,\\\\n(2) Barang siapa tidak memenuhi wajib-kerja selama tiga tahun berturut-turut pada masa, tempat dan dalam jabatan yang ditentukan oleh instansi Pemerintah yang berkuasa, dipidana dengan pidana kurungan selama-lamanya sembilan bulan atau didenda sebanyak-banyaknya seratus ribu rup\",\"subsections\":[]}],\"document_meta_found\":null,\"confidence\":0.8,\"notes\":\"Document meta not found, document creation in DB failed due to a server-side error. Structure is clear: continuation of pasal 5 from possible previous chunk; pasal 6 and 7 fully captured, though pasal 7 is probably truncated (\\\\\"rup\\\\\" is incomplete). Cross-chunk connection is likely, especially for pasal 5 which probably started before this chunk. No duplication risk for 5(1)-(4), 6, 7 in this chunk alone.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2683, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=653, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3336), response_id=None)]\n",
      "Chunk chunk_003 processed with confidence: 0.8\n",
      "Sections found: 3\n",
      "\n",
      "Processing chunk 4/7: chunk_004\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_yyNgeeopnXczIsGuzfMbAXKT', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2388, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2410), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Pejabat Presiden Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_4rR9PKl0VPJiHKV5FLBkL62B', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2430, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=69, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2499), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Pejabat Presiden Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_W3LRQzi94eSHJIP7LmTUtTXC', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2525, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=69, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2594), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"current_chunk_id\":\"chunk_004\",\"context_window_size\":2}', call_id='call_FtZnkiMnoD2qUYPJUXQ1TLfW', name='get_context_for_chunk', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2620, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2656), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_004\",\"identified_sections\":[{\"tag\":\"sanksi\",\"number\":null,\"title\":null,\"content\":\"templat dan dalam jabatan yang ditentukan ... sebagai pelanggaran.\",\"subsections\":[{\"tag\":\"pasal\",\"number\":\"7\",\"title\":null,\"content\":\"(2) Orang yang menolak penempatan atau tugas dalam jabatan tertentu dapat dipidana kurungan atau denda sebagaimana diatur oleh instansi Pemerintah yang berkuasa.\\\\n(3) Barangsiapa mempekerjakan Sarjana yang belum memenuhi kewajiban pasal 5 ayat (2) dapat dipidana kurungan atau denda.\\\\n(4) Ulangan dari pelanggaran ayat (2) dan (3) dapat dipidana lebih berat.\\\\n(5) Segala tindak pidana pada pasal ini dianggap sebagai pelanggaran.\",\"subsections\":[]}]},{\"tag\":\"ketentuan_penutup\",\"number\":null,\"title\":null,\"content\":\"Pasal 8.\\\\nPelaksanaan Undang-undang ini diserahkan kepada Menteri Perburuhan, dan Menteri Pendidikan, Pengetahuan dan Kebudayaan serta Menteri Perguruan Tinggi dan Ilmu Pengetahuan.\\\\nPasal 9.\\\\nUndang-undang ini mulai berlaku pada hari diundangkan. Agar supaya setiap orang dapat mengetahuinya memerintahkan pengundangan Undang-undang ini dengan penempatan dalam Lembaran Negara Republik Indonesia.\",\"subsections\":[{\"tag\":\"pasal\",\"number\":\"8\",\"title\":null,\"content\":\"Pelaksanaan Undang-undang ini diserahkan kepada Menteri Perburuhan, dan Menteri Pendidikan, Pengetahuan dan Kebudayaan serta Menteri Perguruan Tinggi dan Ilmu Pengetahuan.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"9\",\"title\":null,\"content\":\"Undang-undang ini mulai berlaku pada hari diundangkan. Agar supaya setiap orang dapat mengetahuinya memerintahkan pengundangan Undang-undang ini dengan penempatan dalam Lembaran Negara Republik Indonesia.\",\"subsections\":[]}]} ,{\"tag\":\"meta\",\"number\":null,\"title\":null,\"content\":\"Disahkan di Jakarta pada tanggal 29 April 1961. Pejabat Presiden Republik Indonesia, DJUANDA. Diundangkan di Jakarta pada tanggal 29 April 1961. Pejabat Sekretaris Negara, SANTOSO. LEMBARAN NEGARA REPUBLIK INDONESIA TAHUN 1961 NOMOR 207.\",\"subsections\":[]},{\"tag\":\"bab\",\"number\":null,\"title\":\"PENJELASAN ATAS UNDANG-UNDANG NOMOR 8 TAHUN 1961 TENTANG WAJIB KERJA SARJANA\",\"content\":\"\",\"subsections\":[{\"tag\":\"ketentuan_umum\",\"number\":null,\"title\":\"PENJELASAN UMUM\",\"content\":\"Telah lama Pemerintah mengalami kekurangan akan tenaga sarjana ... pelaksanaan garis-garis besar pola pembangunan yang telah ditetapkan oleh Majelis Permusyawaratan Rakyat Sementara. Untuk mengatasi kesulitan yang menghambat Pembangunan Negara ini, disamping mengadakan penghargaan kebendaan yang setepat ...\",\"subsections\":[]}]}],\"document_meta_found\":{\"document_type\":\"Undang-Undang\",\"number\":\"8\",\"year\":\"1961\",\"title\":\"WAJIB KERJA SARJANA\",\"authority\":\"Pejabat Presiden Republik Indonesia\"},\"confidence\":0.95,\"notes\":\"Chunk includes the end of sanksi (Pasal 7), then all of ketentuan penutup (Pasal 8-9), meta (disahkan/diundangkan), and starts penjelasan. Section boundaries are clear, but ketentuan umum (penjelasan umum) is partial and may continue in next chunk. Context check was attempted but creation was blocked by system error; document meta inferred from internal chunk content.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2676, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=826, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3502), response_id=None)]\n",
      "Chunk chunk_004 processed with confidence: 0.95\n",
      "Sections found: 4\n",
      "\n",
      "Processing chunk 5/7: chunk_005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88980/3236137119.py:158: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"processed_at\": datetime.utcnow()\n",
      "/tmp/ipykernel_88980/3236137119.py:168: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"processing_status.last_updated\": datetime.utcnow(),\n",
      "/tmp/ipykernel_88980/3236137119.py:169: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"meta.updated_at\": datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_fP1CqT94o79jJzxh1B3Nbzss', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2351, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2373), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"undang-undang\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_tQ4o9KM1zSaJvJJbP2dmafoR', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2393, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=53, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2446), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"undang-undang\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_TSb8guM7W6B6H2Cw1zQOswBM', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2472, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=53, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2525), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"current_chunk_id\":\"chunk_005\",\"context_window_size\":2}', call_id='call_IOGbjzfuE26YO0ORArfle08E', name='get_context_for_chunk', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2551, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2587), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"chunk_data\":{\"chunk_id\":\"chunk_005\",\"start_pos\":7200,\"end_pos\":9200,\"content\":\"ditetapkan   oleh   Majelis   Permusyawaratan   Rakyat\\\\nSementara.  Untuk  mengatasi  kesulitan  yang  menghambat  Pembangunan  Negara  ini,\\\\ndisamping  mengadakan  penghargaan  kebendaan  yang  setepat-tepatnya  atas  tenaga\\\\nsarjana,  Pemerintah  perlu  mengatur  penggunaan  tenaga  sarjana  yang  sesuai  dengan\\\\njurusannya  dengan  jalan  wajib-kerja  pada  Pemerintah  atau  Badan-badan  swasta  yang\\\\nditunjuk oleh Pemerintah.\\\\nBahwa  pelaksanaan  kewajiban  kerja  sarjana  berdasarkan  Undang-undang  ini  lebih\\\\ndiperlukan khususnya dalam masa peralihan yaitu masa pelaksanaan Manifesto Politik\\\\nRepublik Indonesia tanggal 17 Agustus 1959. Seorang sarjana yang baru lulus dari ujian\\\\npenghabisan  dalam  tempo  sebulan  harus  mendaftarkandiri  pada  Departemen  yang\\\\ndiserahi   Urusan   perguruan   tinggi   yang   meneruskan   daftar   itu   kepada   Dewan\\\\nPenempatan  Sarjana.  Penempatan  itu  seberapa  dapat  akan  disesuaikan  dengan  bakat\\\\ndan kehendak orang yang mendaftarkan.\\\\nPerlu  dikemukakan,  bahwa  undang-undangini  mencabut  Undang-undang  Nomor  8\\\\ntahun 1951 tentang penangguhan pemberian surat ijin untuk berpraktek sebagai doktor\\\\natau   doktor   gigi,   karena   maksudnya   sudah   ditampung   dan   disempurnakan   oleh\\\\nPeraturan ini. Yang maksud dengan peraturan lain ialah peraturan-peraturan mengenai\\\\nwajib    kerja    sarjana,misalnya,    Peraturan    Penguasa    MiliterTertinggi    Nomor\\\\n1132/PMT/1957, selain Peraturan-peraturan yang bertalian dengan wajib Militer.\\\\nAkhirnya  sebagai  tambahan  perlu  dicatat  disini,  bahwa  undang-undang  ini  tidak\\\\nmengurangi wajib kerja karena sesuatu ikatan dinas, yang dilakukan sesudah habisanya\\\\nwajib kerja menurut peraturan ini.\\\\nPENJELASAN PASAL DEMI PASAL.\\\\nPasal 1.\\\\nTiap    sarjana    warganegara    Indonesia    wajib    bekerja    pada    negara    sekurang-\\\\nkurangnnya selama tiga tahun berturut-turut . Sarjana bangsa Asing dibebaskan dari\\\\nkewajiban bekerja ini.\\\\nIjazah yang diperoleh dari Perguruan Tinggi luar  negeri t\",\"char_count\":1993},\"analysis\":{\"identified_sections\":[{\"tag\":\"ketentuan_umum\",\"number\":null,\"title\":null,\"content\":\"Untuk mengatasi kesulitan pembangunan negara, pemerintah mengatur penggunaan tenaga sarjana melalui wajib kerja pada pemerintah atau badan swasta yang ditunjuk. Pelaksanaan kewajiban kerja ini lebih diperlukan pada masa peralihan pelaksanaan Manifesto Politik Republik Indonesia. Setiap sarjana wajib mendaftarkan diri setelah lulus dan penempatan akan disesuaikan dengan bakat serta kehendak pendaftar.\",\"subsections\":[]},{\"tag\":\"ketentuan_penutup\",\"number\":null,\"title\":null,\"content\":\"Undang-undang ini mencabut Undang-undang Nomor 8 Tahun 1951 tentang penangguhan pemberian surat ijin praktik dokter dan dokter gigi. Undang-undang ini tidak mengurangi wajib kerja karena ikatan dinas lain setelah habis wajib kerja menurut peraturan ini.\",\"subsections\":[]},{\"tag\":\"penjelasan\",\"number\":null,\"title\":null,\"content\":\"PENJELASAN PASAL DEMI PASAL.\",\"subsections\":[{\"tag\":\"pasal\",\"number\":\"1\",\"title\":null,\"content\":\"Tiap sarjana WNI wajib bekerja pada negara sekurangnya tiga tahun berturut-turut. Sarjana asing dibebaskan dari kewajiban ini. Ijazah dari perguruan tinggi luar negeri ... (terputus di akhir chunk, kemungkinan berlanjut).\",\"subsections\":[]}]}],\"document_meta_found\":{\"document_type\":\"undang-undang\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"confidence\":0.8,\"notes\":\"Chunk memuat penjelasan umum, ketentuan penutup (pencabutan UU lama dan hubungan dengan peraturan lain), serta awal penjelasan pasal demi pasal, termasuk awal Pasal 1 dan potensi berlanjut di chunk berikut. Terdapat kemungkinan lanjutan untuk penjelasan Pasal 1 di chunk selanjutnya. Struktur harus dihubungkan dengan chunk-chunk sebelumnya/selanjutnya untuk kesinambungan penjelasan pasal. Dokumen belum ada sebelumnya, upaya pembuatan metadata dan penanda bagian didasarkan pada isi chunk ini.\"}}', call_id='call_jibMhRcbyyPJWfef6Sj9gC5T', name='store_chunk_analysis', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2607, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=1113, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3720), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_005\",\"identified_sections\":[{\"tag\":\"ketentuan_umum\",\"number\":null,\"title\":null,\"content\":\"Untuk mengatasi kesulitan pembangunan negara, pemerintah mengatur penggunaan tenaga sarjana melalui wajib kerja pada pemerintah atau badan swasta yang ditunjuk. Pelaksanaan kewajiban kerja ini lebih diperlukan pada masa peralihan pelaksanaan Manifesto Politik Republik Indonesia. Setiap sarjana wajib mendaftarkan diri setelah lulus dan penempatan akan disesuaikan dengan bakat serta kehendak pendaftar.\",\"subsections\":[]},{\"tag\":\"ketentuan_penutup\",\"number\":null,\"title\":null,\"content\":\"Undang-undang ini mencabut Undang-undang Nomor 8 Tahun 1951 tentang penangguhan pemberian surat ijin praktik dokter dan dokter gigi. Undang-undang ini tidak mengurangi wajib kerja karena ikatan dinas lain setelah habis wajib kerja menurut peraturan ini.\",\"subsections\":[]},{\"tag\":\"penjelasan\",\"number\":null,\"title\":null,\"content\":\"PENJELASAN PASAL DEMI PASAL.\",\"subsections\":[{\"tag\":\"pasal\",\"number\":\"1\",\"title\":null,\"content\":\"Tiap sarjana WNI wajib bekerja pada negara sekurangnya tiga tahun berturut-turut. Sarjana asing dibebaskan dari kewajiban ini. Ijazah dari perguruan tinggi luar negeri ... (terputus di akhir chunk, kemungkinan berlanjut).\",\"subsections\":[]}]}],\"document_meta_found\":{\"document_type\":\"undang-undang\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"confidence\":0.8,\"notes\":\"Chunk memuat penjelasan umum, ketentuan penutup (pencabutan UU lama dan hubungan dengan peraturan lain), serta awal penjelasan pasal demi pasal, termasuk awal Pasal 1 dan potensi berlanjut di chunk berikut. Terdapat kemungkinan lanjutan untuk penjelasan Pasal 1 di chunk selanjutnya. Struktur harus dihubungkan dengan chunk-chunk sebelumnya/selanjutnya untuk kesinambungan penjelasan pasal. Penyimpanan data ke database gagal karena dokumen belum dapat dibuat pada tahap ini.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=3739, input_tokens_details=InputTokensDetails(cached_tokens=3712), output_tokens=467, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=4206), response_id=None)]\n",
      "Chunk chunk_005 processed with confidence: 0.8\n",
      "Sections found: 3\n",
      "\n",
      "Processing chunk 6/7: chunk_006\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_6exME3yUB8CW9UUptaBMBYYc', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2360, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2382), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_ocgfnRGo6BG4wz9kvhEaJjs0', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2402, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2452), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_unWrg0pmAjIqrBkOPZSn6pNv', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2478, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2528), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"current_chunk_id\":\"chunk_006\",\"context_window_size\":2}', call_id='call_MQwiqtUltIm0yjjCwCBmps9j', name='get_context_for_chunk', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2554, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2590), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"unknown\",\"number\":null,\"year\":null,\"title\":null,\"authority\":null},\"source_file\":\"unknown\"}', call_id='call_piG4bfMIDf0jclHzk0CP4MYs', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2610, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2660), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_006\",\"identified_sections\":[{\"tag\":\"ketentuan_khusus\",\"number\":null,\"title\":null,\"content\":\"erja pada negara sekurang-kurangnnya selama tiga tahun berturut-turut . Sarjana bangsa Asing dibebaskan dari kewajiban bekerja ini.\\\\nIjazah yang diperoleh dari Perguruan Tinggi luar negeri tingkat Baccalaureat yang telah dihargai sama dengan ijazah Sarjana di Indonesia termasuk dalam pengertian sarjana menurut Peraturan ini (misalnya B.Sc. dari Perguruan Tinggi di Canada dan Australia).\\\\nPara lulusan akadmi tidak setingkat dengan sarjana, karena itu mereka dikecualikan.\\\\nMereka yang sudah menempuh ujian sarjana dinamakan sarjana, akan tetapi bagi pendidikan tinggi Kedokteran, kedokteran gigi, Kedokteran hewan, Apoteker dan Akuntan, ujian sarjana belum merupakan ujian penghabisan Ujian penghabisan bagi mereka adalah ujian dokter, dokter gigi, dokter hewan, apoteker dan akuntan, sehingga yang terkena wajib kerja adalah para dokter, dokter gigi, dokter hewan, apoteker dan akuntan yang baru lulus.\\\\nPembebasan sementara dari seorang sarjana yang sedang menulis atau sedang mempersiapkan thesis untuk mencapai gelar ilmiah \\\\\"Doktor\\\\\", dimaksud untuk memberi kesempatan memajukan ilmupengetahuan di Indonesia. waktu pembebasan itu selama-lamanya 3 tahun.\",\"subsections\":[]},{\"tag\":\"ketentuan_khusus\",\"number\":\"Pasal 2 dan 3\",\"title\":null,\"content\":\"Cukup jelas.\",\"subsections\":[]},{\"tag\":\"ketentuan_khusus\",\"number\":\"Pasal 4\",\"title\":null,\"content\":\"Dalam perkataan wewenang meliputi ketentuan tentang dasar pembagian penempatan sarjana dalam badan-badan baik yang dimiliki, dikuasai atau diawasi oleh Pemerintah.\\\\nDasar penempatan bagi sarjana wanita dapat diperhatikan sifat kodrat wanita.\\\\nSejalan dengan realisasi Pembangunan Semsta, prioritetpenempatan sarjana itu diatur selaras dengan pelaksanaan pembangunan tersebut diatas, dengan urutan sebagai berikut:\\\\na. bidang ekonomi, pendidikan dan penelitian.\\\\nb. Dalam bidang Perusahaan diutamakan Perusahaan Negara atau yang dikuasai oleh negara, dalam hal ini tanpa melalaikan kepentingan Swasta.\",\"subsections\":[]},{\"tag\":\"ketentuan_khusus\",\"number\":\"Pasal 5 dan 6\",\"title\":null,\"content\":\"Cukup jelas.\",\"subsections\":[]},{\"tag\":\"ketentuan_khusus\",\"number\":\"Pasal 7\",\"title\":null,\"content\":\"Maksimum denda disini sengaja dipertinggi unt\",\"subsections\":[]}],\"document_meta_found\":null,\"confidence\":0.8,\"notes\":\"There are multiple references to specific articles (Pasal), mainly explanations for Pasal 2-7. The chunk includes further elucidation of ketentuan khusus, apparently as part of the penjelasan or elucidation section of the document. There may be connected context in previous or next chunks if these explanations begin or end mid-chunk. Document structure could be refined further with additional meta/context.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2686, input_tokens_details=InputTokensDetails(cached_tokens=2560), output_tokens=703, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3389), response_id=None)]\n",
      "Chunk chunk_006 processed with confidence: 0.8\n",
      "Sections found: 5\n",
      "\n",
      "Processing chunk 7/7: chunk_007\n",
      "[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\"}', call_id='call_PfGu77cQ0Dp2sWWQ8T2DnqDt', name='get_document_from_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2084, input_tokens_details=InputTokensDetails(cached_tokens=1536), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2106), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":null,\"year\":\"1961\",\"title\":null,\"authority\":\"Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_azJ94Rp9MvmpdIKhf432MmT8', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2126, input_tokens_details=InputTokensDetails(cached_tokens=2048), output_tokens=58, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2184), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":null,\"year\":\"1961\",\"title\":null,\"authority\":\"Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_8S4uf98voehUf4Fnno751omd', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2210, input_tokens_details=InputTokensDetails(cached_tokens=2176), output_tokens=58, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2268), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":null,\"year\":\"1961\",\"title\":null,\"authority\":\"Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_WaDt8GgILlKST0RP4XNp23ec', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2294, input_tokens_details=InputTokensDetails(cached_tokens=2176), output_tokens=58, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2352), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"current_chunk_id\":\"chunk_007\",\"context_window_size\":2}', call_id='call_gq5jwALZqmnsW7Tn3KXU1gQl', name='get_context_for_chunk', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2378, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2414), response_id=None), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"document_id\":\"doc_e2385b78\",\"meta\":{\"document_type\":\"Undang-Undang\",\"number\":null,\"year\":\"1961\",\"title\":null,\"authority\":\"Republik Indonesia\"},\"source_file\":\"unknown\"}', call_id='call_oauTv2Qcg0pAOifFYkEflrlc', name='create_document_in_db', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=1, input_tokens=2434, input_tokens_details=InputTokensDetails(cached_tokens=2304), output_tokens=58, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=2492), response_id=None), ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"chunk_id\":\"chunk_007\",\"identified_sections\":[{\"tag\":\"ketentuan_umum\",\"number\":null,\"title\":null,\"content\":\"Pasal 5 dan 6.\\\\nCukup jelas.\\\\nPasal 7.\\\\nMaksimum denda disini sengaja dipertinggi untuk menjaga jangan sampai pewajib\\\\nkerja ingkar dari masa tiga tahun.\\\\nDengan adanya hanya ancaman pidana kurungan saja, maka pelanggaran ulangan\\\\ndiharapkan banyak dapat dihindarkan.\\\\nAncaman  hukum  bagi,  penerima  sarjana  termaksud  pada  ayat  3  hanya  berlaku\\\\nuntuk penerimaan sarja (untuk dipekerjakan) yang belum mendaftarkan dantidak\\\\nberlaku lagi yang telah mendaftarkan tetapi belum ditempatkan.\\\\nPasal 8.\\\\nCukup jelas.\\\\nPasal 9.\\\\nPada asasnya semua sarjana sejak diundangkannya undang-undang ini dikenakan\\\\nwajib   kerja   sarjana.   Dengan   sendirinya   termasuk   juga   sarjana-sarjana   lulusan\\\\nsebelum  Undang-undang  ini  berlaku.  Demi  keadilan  pelaksanaannya  diselaraskan\\\\ndengan  kewajiban  kerja  para  dokter  dan  dokter   gigi  sebelum   undang-undang\\\\nberlaku.\\\\nTAMBAHAN LEMBARAN NEGARA REPUBLIK INDONESIA TAHUN 1961 NOMOR\\\\n2270\",\"subsections\":[{\"tag\":\"pasal\",\"number\":\"5 dan 6\",\"title\":null,\"content\":\"Cukup jelas.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"7\",\"title\":null,\"content\":\"Maksimum denda disini sengaja dipertinggi untuk menjaga jangan sampai pewajib\\\\nkerja ingkar dari masa tiga tahun.\\\\nDengan adanya hanya ancaman pidana kurungan saja, maka pelanggaran ulangan\\\\ndiharapkan banyak dapat dihindarkan.\\\\nAncaman  hukum  bagi,  penerima  sarjana  termaksud  pada  ayat  3  hanya  berlaku\\\\nuntuk penerimaan sarja (untuk dipekerjakan) yang belum mendaftarkan dantidak\\\\nberlaku lagi yang telah mendaftarkan tetapi belum ditempatkan.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"8\",\"title\":null,\"content\":\"Cukup jelas.\",\"subsections\":[]},{\"tag\":\"pasal\",\"number\":\"9\",\"title\":null,\"content\":\"Pada asasnya semua sarjana sejak diundangkannya undang-undang ini dikenakan\\\\nwajib   kerja   sarjana.   Dengan   sendirinya   termasuk   juga   sarjana-sarjana   lulusan\\\\nsebelum  Undang-undang  ini  berlaku.  Demi  keadilan  pelaksanaannya  diselaraskan\\\\ndengan  kewajiban  kerja  para  dokter  dan  dokter   gigi  sebelum   undang-undang\\\\nberlaku.\\\\nTAMBAHAN LEMBARAN NEGARA REPUBLIK INDONESIA TAHUN 1961 NOMOR\\\\n2270\",\"subsections\":[]}]}],\"document_meta_found\":{\"document_type\":\"Undang-Undang\",\"number\":null,\"year\":\"1961\",\"title\":null,\"authority\":\"Republik Indonesia\"},\"confidence\":0.9,\"notes\":\"This chunk consists of the penjelasan/petikan for Pasal 5 to 9, which often follow undang-undang sections. The chunk includes closing lines tying to the legislative record. Unable to create or update document due to system/database error; therefore, the analysis is presented only here. No prior context available.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=2518, input_tokens_details=InputTokensDetails(cached_tokens=2432), output_tokens=798, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=3316), response_id=None)]\n",
      "Chunk chunk_007 processed with confidence: 0.9\n",
      "Sections found: 1\n",
      "\n",
      "Document processing completed: doc_e2385b78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'doc_e2385b78'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def process_document_with_sliding_window(document_path, chunk_size=2000, overlap=200):\n",
    "    \"\"\"Process a document with sliding window context\"\"\"\n",
    "    \n",
    "    # Connect to MongoDB\n",
    "    connected = await mongo_manager.connect()\n",
    "    if not connected:\n",
    "        print(\"Failed to connect to MongoDB. Please ensure MongoDB is running.\")\n",
    "        return\n",
    "    \n",
    "    # Load document\n",
    "    try:\n",
    "        with open(document_path, 'r', encoding='utf-8') as f:\n",
    "            document_text = f.read()\n",
    "        \n",
    "        print(f\"Loaded document: {len(document_text)} characters\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {document_path}\")\n",
    "        return\n",
    "    \n",
    "    # Generate a document ID\n",
    "    document_id = f\"doc_{uuid.uuid4().hex[:8]}\"\n",
    "    print(f\"Processing document with ID: {document_id}\")\n",
    "    \n",
    "    # Chunk the document\n",
    "    chunks = simple_chunk_text(document_text, chunk_size, overlap)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    \n",
    "    # Process each chunk sequentially\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\nProcessing chunk {i+1}/{len(chunks)}: {chunk['chunk_id']}\")\n",
    "        \n",
    "        # Create chunk data model\n",
    "        chunk_data = ChunkData(\n",
    "            chunk_id=chunk['chunk_id'],\n",
    "            start_pos=chunk['start_pos'],\n",
    "            end_pos=chunk['end_pos'],\n",
    "            content=chunk['content'],\n",
    "            char_count=chunk['char_count']\n",
    "        )\n",
    "        \n",
    "        # Prepare prompt with option to fetch context\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this chunk of Indonesian legal document text:\n",
    "        \n",
    "        Chunk ID: {chunk['chunk_id']}\n",
    "        Position: {chunk['start_pos']} to {chunk['end_pos']}\n",
    "        \n",
    "        Content:\n",
    "        {chunk['content']}\n",
    "        \n",
    "        This is chunk {i+1} of {len(chunks)} from document ID: {document_id}\n",
    "        \n",
    "        If this is not the first chunk, you may want to fetch context from previous chunks.\n",
    "        You can decide whether to use get_context_for_chunk based on your analysis needs.\n",
    "        \n",
    "        First, you need to check if the document_id exists in mongodb, if not create it.\n",
    "        Before returning and finishing, remember to add/update the sections of the document_id in mongodb.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Process the chunk\n",
    "        result = await Runner.run(document_analyzer, prompt)\n",
    "        analysis = result.final_output\n",
    "        \n",
    "        print(result.raw_responses)\n",
    "        print(f\"Chunk {chunk['chunk_id']} processed with confidence: {analysis.confidence}\")\n",
    "        print(f\"Sections found: {len(analysis.identified_sections)}\")\n",
    "        \n",
    "    # Update processing status to completed\n",
    "    # await update_processing_status(document_id, \"completed\")\n",
    "    print(f\"\\nDocument processing completed: {document_id}\")\n",
    "    \n",
    "    return document_id\n",
    "\n",
    "await process_document_with_sliding_window(sample_doc_path, chunk_size=2000, overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB: hukum_terbuka\n",
      "Testing with document ID: test_doc_d744cc54\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:62\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n",
      "\u001b[32m     57\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n",
      "\u001b[32m     58\u001b[39m     model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n",
      "\u001b[32m     59\u001b[39m     model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n",
      "\u001b[32m     60\u001b[39m     disabled=tracing.is_disabled(),\n",
      "\u001b[32m     61\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n",
      "\u001b[32m     63\u001b[39m         system_instructions,\n",
      "\u001b[32m     64\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n",
      "\u001b[32m     65\u001b[39m         model_settings,\n",
      "\u001b[32m     66\u001b[39m         tools,\n",
      "\u001b[32m     67\u001b[39m         output_schema,\n",
      "\u001b[32m     68\u001b[39m         handoffs,\n",
      "\u001b[32m     69\u001b[39m         span_generation,\n",
      "\u001b[32m     70\u001b[39m         tracing,\n",
      "\u001b[32m     71\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[32m     72\u001b[39m     )\n",
      "\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:252\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, span, tracing, stream)\u001b[39m\n",
      "\u001b[32m    248\u001b[39m stream_options = ChatCmplHelpers.get_stream_options_param(\n",
      "\u001b[32m    249\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_client(), model_settings, stream=stream\n",
      "\u001b[32m    250\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_client().chat.completions.create(\n",
      "\u001b[32m    253\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n",
      "\u001b[32m    254\u001b[39m     messages=converted_messages,\n",
      "\u001b[32m    255\u001b[39m     tools=converted_tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n",
      "\u001b[32m    256\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n",
      "\u001b[32m    257\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n",
      "\u001b[32m    258\u001b[39m     frequency_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.frequency_penalty),\n",
      "\u001b[32m    259\u001b[39m     presence_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.presence_penalty),\n",
      "\u001b[32m    260\u001b[39m     max_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n",
      "\u001b[32m    261\u001b[39m     tool_choice=tool_choice,\n",
      "\u001b[32m    262\u001b[39m     response_format=response_format,\n",
      "\u001b[32m    263\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n",
      "\u001b[32m    264\u001b[39m     stream=stream,\n",
      "\u001b[32m    265\u001b[39m     stream_options=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(stream_options),\n",
      "\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(store),\n",
      "\u001b[32m    267\u001b[39m     reasoning_effort=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(reasoning_effort),\n",
      "\u001b[32m    268\u001b[39m     extra_headers={**HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n",
      "\u001b[32m    269\u001b[39m     extra_query=model_settings.extra_query,\n",
      "\u001b[32m    270\u001b[39m     extra_body=model_settings.extra_body,\n",
      "\u001b[32m    271\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n",
      "\u001b[32m    272\u001b[39m )\n",
      "\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, ChatCompletion):\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/trace/op.py:1224\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m   1222\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n",
      "\u001b[32m   1223\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:  \u001b[38;5;66;03m# pyright: ignore[reportRedeclaration]\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m     res, _ = \u001b[38;5;28;01mawait\u001b[39;00m _call_async_func(\n",
      "\u001b[32m   1225\u001b[39m         cast(Op[P, R], wrapper), *args, __should_raise=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs\n",
      "\u001b[32m   1226\u001b[39m     )\n",
      "\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/trace/op.py:636\u001b[39m, in \u001b[36m_call_async_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m    637\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai/openai_sdk.py:366\u001b[39m, in \u001b[36mcreate_wrapper_async.<locals>.wrapper.<locals>._add_stream_options.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m    365\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n",
      "\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/resources/chat/completions/completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n",
      "\u001b[32m   2027\u001b[39m validate_response_format(response_format)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n",
      "\u001b[32m   2029\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m   2030\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n",
      "\u001b[32m   2031\u001b[39m         {\n",
      "\u001b[32m   2032\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n",
      "\u001b[32m   2033\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n",
      "\u001b[32m   2034\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n",
      "\u001b[32m   2035\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n",
      "\u001b[32m   2036\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n",
      "\u001b[32m   2037\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n",
      "\u001b[32m   2038\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n",
      "\u001b[32m   2039\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n",
      "\u001b[32m   2040\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n",
      "\u001b[32m   2041\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n",
      "\u001b[32m   2042\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n",
      "\u001b[32m   2043\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n",
      "\u001b[32m   2044\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n",
      "\u001b[32m   2045\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n",
      "\u001b[32m   2046\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n",
      "\u001b[32m   2047\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n",
      "\u001b[32m   2048\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n",
      "\u001b[32m   2049\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n",
      "\u001b[32m   2050\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n",
      "\u001b[32m   2051\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n",
      "\u001b[32m   2052\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n",
      "\u001b[32m   2053\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n",
      "\u001b[32m   2054\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n",
      "\u001b[32m   2055\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n",
      "\u001b[32m   2056\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n",
      "\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n",
      "\u001b[32m   2058\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n",
      "\u001b[32m   2059\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n",
      "\u001b[32m   2060\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n",
      "\u001b[32m   2061\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n",
      "\u001b[32m   2062\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n",
      "\u001b[32m   2063\u001b[39m         },\n",
      "\u001b[32m   2064\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n",
      "\u001b[32m   2065\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n",
      "\u001b[32m   2066\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n",
      "\u001b[32m   2067\u001b[39m     ),\n",
      "\u001b[32m   2068\u001b[39m     options=make_request_options(\n",
      "\u001b[32m   2069\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n",
      "\u001b[32m   2070\u001b[39m     ),\n",
      "\u001b[32m   2071\u001b[39m     cast_to=ChatCompletion,\n",
      "\u001b[32m   2072\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[32m   2073\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n",
      "\u001b[32m   2074\u001b[39m )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1739\u001b[39m opts = FinalRequestOptions.construct(\n",
      "\u001b[32m   1740\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n",
      "\u001b[32m   1741\u001b[39m )\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/openai/_base_client.py:1484\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n",
      "\u001b[32m   1485\u001b[39m         request,\n",
      "\u001b[32m   1486\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n",
      "\u001b[32m   1487\u001b[39m         **kwargs,\n",
      "\u001b[32m   1488\u001b[39m     )\n",
      "\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n",
      "\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n",
      "\u001b[32m   1630\u001b[39m     request,\n",
      "\u001b[32m   1631\u001b[39m     auth=auth,\n",
      "\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n",
      "\u001b[32m   1633\u001b[39m     history=[],\n",
      "\u001b[32m   1634\u001b[39m )\n",
      "\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n",
      "\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n",
      "\u001b[32m   1658\u001b[39m         request,\n",
      "\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n",
      "\u001b[32m   1660\u001b[39m         history=history,\n",
      "\u001b[32m   1661\u001b[39m     )\n",
      "\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n",
      "\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n",
      "\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n",
      "\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n",
      "\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n",
      "\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n",
      "\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n",
      "\u001b[32m    237\u001b[39m         pool_request.request\n",
      "\u001b[32m    238\u001b[39m     )\n",
      "\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n",
      "\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n",
      "\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n",
      "\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n",
      "\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n",
      "\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n",
      "\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n",
      "\u001b[32m    100\u001b[39m     (\n",
      "\u001b[32m    101\u001b[39m         http_version,\n",
      "\u001b[32m    102\u001b[39m         status,\n",
      "\u001b[32m    103\u001b[39m         reason_phrase,\n",
      "\u001b[32m    104\u001b[39m         headers,\n",
      "\u001b[32m    105\u001b[39m         trailing_data,\n",
      "\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n",
      "\u001b[32m    107\u001b[39m     trace.return_value = (\n",
      "\u001b[32m    108\u001b[39m         http_version,\n",
      "\u001b[32m    109\u001b[39m         status,\n",
      "\u001b[32m    110\u001b[39m         reason_phrase,\n",
      "\u001b[32m    111\u001b[39m         headers,\n",
      "\u001b[32m    112\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n",
      "\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n",
      "\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n",
      "\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n",
      "\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n",
      "\u001b[32m    219\u001b[39m     )\n",
      "\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n",
      "\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n",
      "\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n",
      "\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/streams/tls.py:219\u001b[39m, in \u001b[36mTLSStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n",
      "\u001b[32m    218\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m = \u001b[32m65536\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_sslobject_method(\u001b[38;5;28mself\u001b[39m._ssl_object.read, max_bytes)\n",
      "\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/streams/tls.py:162\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n",
      "\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n",
      "\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n",
      "\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/anyio/_backends/_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n",
      "\u001b[32m   1253\u001b[39m \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n",
      "\u001b[32m   1255\u001b[39m \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "\u001b[31mCancelledError\u001b[39m: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 13\u001b[39m\n",
      "\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting with document ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_doc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Test document creation\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n",
      "\u001b[32m     14\u001b[39m     document_analyzer,\n",
      "\u001b[32m     15\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     16\u001b[39m \u001b[33m    Create a new document in the database with the following information:\u001b[39m\n",
      "\u001b[32m     17\u001b[39m \u001b[33m    - Document ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_doc_id\u001b[38;5;132;01m}\u001b[39;00m\n",
      "\u001b[32m     18\u001b[39m \u001b[33m    - Document Type: UU\u001b[39m\n",
      "\u001b[32m     19\u001b[39m \u001b[33m    - Number: 8\u001b[39m\n",
      "\u001b[32m     20\u001b[39m \u001b[33m    - Year: 1961\u001b[39m\n",
      "\u001b[32m     21\u001b[39m \u001b[33m    - Title: Undang-Undang tentang Wajib Kerja\u001b[39m\n",
      "\u001b[32m     22\u001b[39m \u001b[33m    - Authority: Presiden Republik Indonesia\u001b[39m\n",
      "\u001b[32m     23\u001b[39m \u001b[33m    - Source File: raw/UU_8_1961.txt\u001b[39m\n",
      "\u001b[32m     24\u001b[39m \n",
      "\u001b[32m     25\u001b[39m \u001b[33m    Then retrieve the document to confirm it was created.\u001b[39m\n",
      "\u001b[32m     26\u001b[39m \u001b[33m    (retrieve just with the document ID str, don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt include the dic, eg just \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_doc_eb9acd2b\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\n",
      "\u001b[32m     27\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[32m     28\u001b[39m )\n",
      "\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDocument creation test result:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.final_output.model_dump_json(indent=\u001b[32m2\u001b[39m))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:218\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n",
      "\u001b[32m    213\u001b[39m logger.debug(\n",
      "\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m    215\u001b[39m )\n",
      "\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n",
      "\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n",
      "\u001b[32m    220\u001b[39m             starting_agent,\n",
      "\u001b[32m    221\u001b[39m             starting_agent.input_guardrails\n",
      "\u001b[32m    222\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n",
      "\u001b[32m    223\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n",
      "\u001b[32m    224\u001b[39m             context_wrapper,\n",
      "\u001b[32m    225\u001b[39m         ),\n",
      "\u001b[32m    226\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n",
      "\u001b[32m    227\u001b[39m             agent=current_agent,\n",
      "\u001b[32m    228\u001b[39m             all_tools=all_tools,\n",
      "\u001b[32m    229\u001b[39m             original_input=original_input,\n",
      "\u001b[32m    230\u001b[39m             generated_items=generated_items,\n",
      "\u001b[32m    231\u001b[39m             hooks=hooks,\n",
      "\u001b[32m    232\u001b[39m             context_wrapper=context_wrapper,\n",
      "\u001b[32m    233\u001b[39m             run_config=run_config,\n",
      "\u001b[32m    234\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n",
      "\u001b[32m    235\u001b[39m             tool_use_tracker=tool_use_tracker,\n",
      "\u001b[32m    236\u001b[39m             previous_response_id=previous_response_id,\n",
      "\u001b[32m    237\u001b[39m         ),\n",
      "\u001b[32m    238\u001b[39m     )\n",
      "\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n",
      "\u001b[32m    241\u001b[39m         agent=current_agent,\n",
      "\u001b[32m    242\u001b[39m         all_tools=all_tools,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n",
      "\u001b[32m    251\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:762\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n",
      "\u001b[32m    759\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n",
      "\u001b[32m    760\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n",
      "\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n",
      "\u001b[32m    763\u001b[39m     agent,\n",
      "\u001b[32m    764\u001b[39m     system_prompt,\n",
      "\u001b[32m    765\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n",
      "\u001b[32m    766\u001b[39m     output_schema,\n",
      "\u001b[32m    767\u001b[39m     all_tools,\n",
      "\u001b[32m    768\u001b[39m     handoffs,\n",
      "\u001b[32m    769\u001b[39m     context_wrapper,\n",
      "\u001b[32m    770\u001b[39m     run_config,\n",
      "\u001b[32m    771\u001b[39m     tool_use_tracker,\n",
      "\u001b[32m    772\u001b[39m     previous_response_id,\n",
      "\u001b[32m    773\u001b[39m )\n",
      "\u001b[32m    775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n",
      "\u001b[32m    776\u001b[39m     agent=agent,\n",
      "\u001b[32m    777\u001b[39m     original_input=original_input,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     tool_use_tracker=tool_use_tracker,\n",
      "\u001b[32m    787\u001b[39m )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/run.py:921\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n",
      "\u001b[32m    918\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n",
      "\u001b[32m    919\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n",
      "\u001b[32m    922\u001b[39m     system_instructions=system_prompt,\n",
      "\u001b[32m    923\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n",
      "\u001b[32m    924\u001b[39m     model_settings=model_settings,\n",
      "\u001b[32m    925\u001b[39m     tools=all_tools,\n",
      "\u001b[32m    926\u001b[39m     output_schema=output_schema,\n",
      "\u001b[32m    927\u001b[39m     handoffs=handoffs,\n",
      "\u001b[32m    928\u001b[39m     tracing=get_model_tracing_impl(\n",
      "\u001b[32m    929\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n",
      "\u001b[32m    930\u001b[39m     ),\n",
      "\u001b[32m    931\u001b[39m     previous_response_id=previous_response_id,\n",
      "\u001b[32m    932\u001b[39m )\n",
      "\u001b[32m    934\u001b[39m context_wrapper.usage.add(new_response.usage)\n",
      "\u001b[32m    936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/models/openai_chatcompletions.py:57\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n",
      "\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\n",
      "\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m     48\u001b[39m     system_instructions: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     previous_response_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m     56\u001b[39m ) -> ModelResponse:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n",
      "\u001b[32m     58\u001b[39m         model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n",
      "\u001b[32m     59\u001b[39m         model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n",
      "\u001b[32m     60\u001b[39m         disabled=tracing.is_disabled(),\n",
      "\u001b[32m     61\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n",
      "\u001b[32m     62\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n",
      "\u001b[32m     63\u001b[39m             system_instructions,\n",
      "\u001b[32m     64\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[32m     72\u001b[39m         )\n",
      "\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/spans.py:237\u001b[39m, in \u001b[36mSpanImpl.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n",
      "\u001b[32m    234\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mGeneratorExit, skipping span reset\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    235\u001b[39m     reset_current = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreset_current\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_current\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/spans.py:222\u001b[39m, in \u001b[36mSpanImpl.finish\u001b[39m\u001b[34m(self, reset_current)\u001b[39m\n",
      "\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m._ended_at = util.time_iso()\n",
      "\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_span_end\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_current \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prev_span_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    224\u001b[39m     Scope.reset_current_span(\u001b[38;5;28mself\u001b[39m._prev_span_token)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/agents/tracing/setup.py:65\u001b[39m, in \u001b[36mSynchronousMultiTracingProcessor.on_span_end\u001b[39m\u001b[34m(self, span)\u001b[39m\n",
      "\u001b[32m     61\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m     62\u001b[39m \u001b[33;03mCalled when a span is finished.\u001b[39;00m\n",
      "\u001b[32m     63\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._processors:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_span_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:363\u001b[39m, in \u001b[36mWeaveTracingProcessor.on_span_end\u001b[39m\u001b[34m(self, span)\u001b[39m\n",
      "\u001b[32m    361\u001b[39m span_name = _call_name(span)\n",
      "\u001b[32m    362\u001b[39m span_type = _call_type(span)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m log_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# For Response spans, create the call here so we can include input data\u001b[39;00m\n",
      "\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[32m    367\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.ResponseSpanData)\n",
      "\u001b[32m    368\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m span.span_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._span_calls\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m ):\n",
      "\u001b[32m    372\u001b[39m     \u001b[38;5;66;03m# Create attributes\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:289\u001b[39m, in \u001b[36mWeaveTracingProcessor._log_data\u001b[39m\u001b[34m(self, span)\u001b[39m\n",
      "\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail_log_data(span)\n",
      "\u001b[32m    288\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.GenerationSpanData):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generation_log_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    290\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(span.span_data, tracing.CustomSpanData):\n",
      "\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._custom_log_data(span)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/HukumTerbuka/.venv/lib64/python3.13/site-packages/weave/integrations/openai_agents/openai_agents.py:230\u001b[39m, in \u001b[36mWeaveTracingProcessor._generation_log_data\u001b[39m\u001b[34m(self, span)\u001b[39m\n",
      "\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generation_log_data\u001b[39m(\n",
      "\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m, span: tracing.Span[tracing.GenerationSpanData]\n",
      "\u001b[32m    220\u001b[39m ) -> WeaveDataDict:\n",
      "\u001b[32m    221\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Extract log data from a generation span.\"\"\"\u001b[39;00m\n",
      "\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WeaveDataDict(\n",
      "\u001b[32m    223\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.input},\n",
      "\u001b[32m    224\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.output},\n",
      "\u001b[32m    225\u001b[39m         metadata={\n",
      "\u001b[32m    226\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.model,\n",
      "\u001b[32m    227\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.model_config,\n",
      "\u001b[32m    228\u001b[39m         },\n",
      "\u001b[32m    229\u001b[39m         metrics={\n",
      "\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mspan\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspan_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43musage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mtotal_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n",
      "\u001b[32m    231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_tokens\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.usage.get(\u001b[33m\"\u001b[39m\u001b[33mprompt_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n",
      "\u001b[32m    232\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcompletion_tokens\u001b[39m\u001b[33m\"\u001b[39m: span.span_data.usage.get(\u001b[33m\"\u001b[39m\u001b[33mcompletion_tokens\u001b[39m\u001b[33m\"\u001b[39m),\n",
      "\u001b[32m    233\u001b[39m         },\n",
      "\u001b[32m    234\u001b[39m         error=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m    235\u001b[39m     )\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Test MongoDB integration\n",
    "# Connect to MongoDB\n",
    "connected = await mongo_manager.connect()\n",
    "if not connected:\n",
    "    print(\"Failed to connect to MongoDB. Please ensure MongoDB is running.\")\n",
    "\n",
    "# Generate a test document ID\n",
    "test_doc_id = f\"test_doc_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "print(f\"Testing with document ID: {test_doc_id}\")\n",
    "\n",
    "# Test document creation\n",
    "result = await Runner.run(\n",
    "    document_analyzer,\n",
    "    f\"\"\"\n",
    "    Create a new document in the database with the following information:\n",
    "    - Document ID: {test_doc_id}\n",
    "    - Document Type: UU\n",
    "    - Number: 8\n",
    "    - Year: 1961\n",
    "    - Title: Undang-Undang tentang Wajib Kerja\n",
    "    - Authority: Presiden Republik Indonesia\n",
    "    - Source File: raw/UU_8_1961.txt\n",
    "    \n",
    "    Then retrieve the document to confirm it was created.\n",
    "    (retrieve just with the document ID str, don't include the dic, eg just \"test_doc_eb9acd2b\")\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Document creation test result:\")\n",
    "print(result.final_output.model_dump_json(indent=2))\n",
    "print(result.raw_responses)\n",
    "\n",
    "print(test_doc_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "document_id = \"doc_c64169e0\"\n",
    "document = await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": document_id}\n",
    "        )\n",
    "print(document)\n",
    "if document:\n",
    "    # Convert ObjectId to string for JSON serialization\n",
    "    document[\"_id\"] = str(document[\"_id\"])\n",
    "    json.dumps(document, default=str, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": \"doc_2c2d2633\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coretan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
