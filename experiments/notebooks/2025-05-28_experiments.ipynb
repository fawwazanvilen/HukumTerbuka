{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# OpenAI client\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Weave for tracing\n",
    "import weave\n",
    "\n",
    "# MongoDB\n",
    "import pymongo\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "\n",
    "# Pydantic models (reuse your existing models)\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weave Tracing\n",
    "weave.init('HukumTerbuka')\n",
    "\n",
    "# Set up the OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\") or os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document: 11846 characters\n",
      "First 500 characters:\n",
      "PRESIDEN\n",
      "REPUBLIK INDONESIA\n",
      "UNDANG-UNDANG REPUBLIK INDONESIA\n",
      "NOMOR 8 TAHUN 1961\n",
      "TENTANG\n",
      "WAJIB KERJA SARJANA\n",
      "PRESIDEN REPUBLIK INDONESIA,\n",
      "Menimbang:a.bahwa ilmu dan keahlian azasnya untuk mengabdi kepada tanah\n",
      "air, karenanya perlu dikembangkan dan dilaksanakan.\n",
      "b.bahwa  dalam  rangka  pembangunan  nasional  semesta  berencana\n",
      "sangat diperlukan tenaga sarjana dari perbagai jurusan;\n",
      "c.bahwa agar penempatan dan penggunaan tenaga sarjana tersebut\n",
      "teratur  dan  merata  maka  perlu  diadakan  peraturan\n",
      "...\n",
      "\n",
      "Created 7 chunks\n"
     ]
    }
   ],
   "source": [
    "def simple_chunk_text(text: str, chunk_size: int = 2000, overlap: int = 200) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Simple chunking function that splits text every chunk_size characters\n",
    "    with optional overlap to maintain context.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    chunk_id = 1\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk_text = text[start:end]\n",
    "        \n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"chunk_{chunk_id:03d}\",\n",
    "            \"start_pos\": start,\n",
    "            \"end_pos\": min(end, len(text)),\n",
    "            \"content\": chunk_text,\n",
    "            \"char_count\": len(chunk_text)\n",
    "        })\n",
    "        \n",
    "        # Move start position, accounting for overlap\n",
    "        start = end - overlap if end < len(text) else len(text)\n",
    "        chunk_id += 1\n",
    "        \n",
    "        # Safety break to avoid infinite loops\n",
    "        if chunk_id > 100:  # Adjust as needed\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Chunk Sample Doc\n",
    "# Load the sample document\n",
    "sample_doc_path = \"../../raw/UU_8_1961.txt\"\n",
    "\n",
    "try:\n",
    "    with open(sample_doc_path, 'r', encoding='utf-8') as f:\n",
    "        document_text = f.read()\n",
    "    \n",
    "    print(f\"Loaded document: {len(document_text)} characters\")\n",
    "    print(f\"First 500 characters:\")\n",
    "    print(document_text[:500])\n",
    "    print(\"...\")\n",
    "    \n",
    "    # Chunk the document\n",
    "    chunks = simple_chunk_text(document_text, chunk_size=2000, overlap=200)\n",
    "    print(f\"\\nCreated {len(chunks)} chunks\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {sample_doc_path}\")\n",
    "    print(\"Please check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic document structure models\n",
    "class DocumentMeta(BaseModel):\n",
    "    document_type: str  # UU, PP, Perpres, etc.\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class DocumentSection(BaseModel):\n",
    "    tag: str  # pasal, bab, ayat, konsideran, etc.\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['DocumentSection'] = []\n",
    "\n",
    "class LegalDocument(BaseModel):\n",
    "    meta: DocumentMeta\n",
    "    preface: List[DocumentSection] = []\n",
    "    preamble: List[DocumentSection] = []\n",
    "    body: List[DocumentSection] = []\n",
    "    conclusions: List[DocumentSection] = []\n",
    "\n",
    "# Fix the forward reference\n",
    "DocumentSection.model_rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for MongoDB operations\n",
    "class DocumentMetaInput(BaseModel):\n",
    "    document_type: str\n",
    "    number: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    authority: Optional[str] = None\n",
    "\n",
    "class SectionItem(BaseModel):\n",
    "    tag: str\n",
    "    number: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    content: str\n",
    "    subsections: List['SectionItem'] = Field(default_factory=list)\n",
    "\n",
    "# Fix the forward reference\n",
    "SectionItem.model_rebuild()\n",
    "\n",
    "class ChunkData(BaseModel):\n",
    "    chunk_id: str\n",
    "    start_pos: int\n",
    "    end_pos: int\n",
    "    content: str\n",
    "    char_count: Optional[int] = None\n",
    "\n",
    "class AnalysisResult(BaseModel):\n",
    "    identified_sections: List[SectionItem]\n",
    "    document_meta_found: Optional[DocumentMetaInput] = None\n",
    "    confidence: float\n",
    "    notes: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "# MongoDB connection setup\n",
    "class MongoDBManager:\n",
    "    def __init__(self, connection_string: str = \"mongodb://localhost:27017/\", db_name: str = \"hukum_terbuka\"):\n",
    "        self.connection_string = connection_string\n",
    "        self.db_name = db_name\n",
    "        self.client = None\n",
    "        self.db = None\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Connect to MongoDB\"\"\"\n",
    "        self.client = AsyncIOMotorClient(self.connection_string)\n",
    "        self.db = self.client[self.db_name]\n",
    "        \n",
    "        # Test connection\n",
    "        try:\n",
    "            await self.client.admin.command('ping')\n",
    "            print(f\"✅ Connected to MongoDB: {self.db_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ MongoDB connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def close(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        if self.client:\n",
    "            self.client.close()\n",
    "\n",
    "# Initialize MongoDB manager\n",
    "mongo_manager = MongoDBManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB document schema - matches our Pydantic models but with MongoDB-specific fields\n",
    "class MongoDocument:\n",
    "    \"\"\"\n",
    "    MongoDB document structure for legal documents\n",
    "    \n",
    "    Structure:\n",
    "    {\n",
    "        \"_id\": ObjectId,\n",
    "        \"document_id\": \"unique_doc_id\",\n",
    "        \"meta\": {\n",
    "            \"document_type\": \"UU\",\n",
    "            \"number\": \"8\",\n",
    "            \"year\": \"1961\",\n",
    "            \"title\": \"...\",\n",
    "            \"authority\": \"...\",\n",
    "            \"source_file\": \"...\",\n",
    "            \"created_at\": datetime,\n",
    "            \"updated_at\": datetime\n",
    "        },\n",
    "        \"structure\": {\n",
    "            \"preface\": [...],\n",
    "            \"preamble\": [...],\n",
    "            \"body\": [...],\n",
    "            \"conclusions\": [...]\n",
    "        },\n",
    "        \"processing_status\": {\n",
    "            \"total_chunks\": 10,\n",
    "            \"processed_chunks\": 5,\n",
    "            \"status\": \"processing|completed|failed\",\n",
    "            \"last_updated\": datetime\n",
    "        },\n",
    "        \"chunks\": [\n",
    "            {\n",
    "                \"chunk_id\": \"chunk_001\",\n",
    "                \"start_pos\": 0,\n",
    "                \"end_pos\": 2000,\n",
    "                \"content\": \"...\",\n",
    "                \"analysis\": {...},\n",
    "                \"processed_at\": datetime\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Collection names\n",
    "COLLECTIONS = {\n",
    "    \"documents\": \"legal_documents\",\n",
    "    \"chunks\": \"document_chunks\",\n",
    "    \"processing_logs\": \"processing_logs\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_document_in_db\",\n",
    "            \"description\": \"Create a new legal document in MongoDB. All metadata fields should be provided; use null for optional text fields if not applicable.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique identifier for the document.\"\n",
    "                    },\n",
    "                    \"meta\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"Metadata for the legal document. All fields (document_type, number, year, title, authority) must be specified; use null for number, year, title, or authority if they are not applicable or unknown.\",\n",
    "                        \"properties\": {\n",
    "                            \"document_type\": {\"type\": \"string\", \"description\": \"Type of the document (e.g., UU, PP).\"},\n",
    "                            \"number\": {\"type\": [\"string\", \"null\"], \"description\": \"Document number. Null if not applicable.\"},\n",
    "                            \"year\": {\"type\": [\"string\", \"null\"], \"description\": \"Year of the document. Null if not applicable.\"},\n",
    "                            \"title\": {\"type\": [\"string\", \"null\"], \"description\": \"Official title of the document. Null if not applicable.\"},\n",
    "                            \"authority\": {\"type\": [\"string\", \"null\"], \"description\": \"Issuing authority. Null if not applicable.\"}\n",
    "                        },\n",
    "                        \"required\": [\"document_type\", \"number\", \"year\", \"title\", \"authority\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"source_file\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to the source file of the document.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"meta\", \"source_file\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_document_from_db\",\n",
    "            \"description\": \"Retrieve a legal document from MongoDB using its unique document_id.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"The unique identifier of the document to retrieve.\"}\n",
    "                },\n",
    "                \"required\": [\"document_id\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_context_for_chunk\",\n",
    "            \"description\": \"Fetch context from previously processed chunks for a given document. Includes previous chunk analyses, overall document structure, and metadata.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the document.\"},\n",
    "                    \"current_chunk_id\": {\"type\": \"string\", \"description\": \"ID of the current chunk being processed (e.g., chunk_001).\"},\n",
    "                    \"context_window_size\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"default\": 1,\n",
    "                        \"description\": \"Number of previous chunks to include in the context. Defaults to 1.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"current_chunk_id\", \"context_window_size\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"update_document_section\",\n",
    "            \"description\": \"Update/replace an entire specific section (preface, preamble, body, or conclusions) of a legal document. The provided section_data will overwrite the existing content of that section. Each item in section_data must be a complete SectionItem object.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the document.\"},\n",
    "                    \"section_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"preface\", \"preamble\", \"body\", \"conclusions\"],\n",
    "                        \"description\": \"The type of section to update.\"\n",
    "                    },\n",
    "                    \"section_data\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"A list of SectionItem objects that will form the new content for the specified section. Each item must be a complete SectionItem, including all its fields (tag, number, title, content, subsections). Use null for optional text fields and empty list for subsections if not applicable.\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"tag\": {\"type\": \"string\", \"description\": \"Tag of the section item (e.g., pasal, ayat).\"},\n",
    "                                \"number\": {\"type\": [\"string\", \"null\"], \"description\": \"Number of the section item. Null if not applicable.\"},\n",
    "                                \"title\": {\"type\": [\"string\", \"null\"], \"description\": \"Title of the section item. Null if not applicable.\"},\n",
    "                                \"content\": {\"type\": \"string\", \"description\": \"Content of the section item.\"},\n",
    "                                \"subsections\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Nested subsections. Each must also be a complete SectionItem object. Provide an empty list if no subsections.\",\n",
    "                                    \"items\": {\"$ref\": \"#/properties/section_data/items\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"tag\", \"number\", \"title\", \"content\", \"subsections\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"section_type\", \"section_data\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_document_section\",\n",
    "            \"description\": \"Add a new item (as a SectionItem object) to a specific document section (preface, preamble, body, or conclusions). The new item is appended to the existing items in that section.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the document.\"},\n",
    "                    \"section_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"preface\", \"preamble\", \"body\", \"conclusions\"],\n",
    "                        \"description\": \"The type of section to add the new item to.\"\n",
    "                    },\n",
    "                    \"section_item\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"The SectionItem object to add. It must be a complete SectionItem, including all its fields (tag, number, title, content, subsections). Use null for optional text fields and empty list for subsections if not applicable.\",\n",
    "                        \"properties\": {\n",
    "                            \"tag\": {\"type\": \"string\", \"description\": \"Tag of the new section item (e.g., pasal, ayat).\"},\n",
    "                            \"number\": {\"type\": [\"string\", \"null\"], \"description\": \"Number of the new section item. Null if not applicable.\"},\n",
    "                            \"title\": {\"type\": [\"string\", \"null\"], \"description\": \"Title of the new section item. Null if not applicable.\"},\n",
    "                            \"content\": {\"type\": \"string\", \"description\": \"Content of the new section item.\"},\n",
    "                            \"subsections\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Nested subsections for the new item. Each must also be a complete SectionItem object. Provide an empty list if no subsections.\",\n",
    "                                \"items\": {\"$ref\": \"#/properties/section_item\"}\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"tag\", \"number\", \"title\", \"content\", \"subsections\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"section_type\", \"section_item\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"store_chunk_analysis\",\n",
    "            \"description\": \"Store the analysis results for a specific chunk of a document. This includes identified sections, found document metadata, confidence score, and notes. All fields within chunk_data and analysis (and their sub-objects like SectionItem or DocumentMetaInput) must be provided; use null or empty strings/lists where appropriate for optional/empty values.\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the document.\"},\n",
    "                    \"chunk_data\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"Information about the processed chunk. All fields must be provided; use null for char_count if not applicable.\",\n",
    "                        \"properties\": {\n",
    "                            \"chunk_id\": {\"type\": \"string\", \"description\": \"ID of the chunk.\"},\n",
    "                            \"start_pos\": {\"type\": \"integer\", \"description\": \"Start position of the chunk in the original document.\"},\n",
    "                            \"end_pos\": {\"type\": \"integer\", \"description\": \"End position of the chunk in the original document.\"},\n",
    "                            \"content\": {\"type\": \"string\", \"description\": \"The text content of the chunk.\"},\n",
    "                            \"char_count\": {\"type\": [\"integer\", \"null\"], \"description\": \"Character count of the chunk. Null if not applicable.\"}\n",
    "                        },\n",
    "                        \"required\": [\"chunk_id\", \"start_pos\", \"end_pos\", \"content\", \"char_count\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"analysis\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"The analysis result for the chunk. All fields must be provided. For 'document_meta_found', provide the metadata object or null. For 'identified_sections', each item must be a complete SectionItem. 'notes' can be an empty string.\",\n",
    "                        \"properties\": {\n",
    "                            \"identified_sections\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"List of sections identified in the chunk. Each item must be a complete SectionItem object.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"tag\": {\"type\": \"string\", \"description\": \"Tag of the identified section (e.g., pasal, ayat).\"},\n",
    "                                        \"number\": {\"type\": [\"string\", \"null\"], \"description\": \"Number of the section. Null if not applicable.\"},\n",
    "                                        \"title\": {\"type\": [\"string\", \"null\"], \"description\": \"Title of the section. Null if not applicable.\"},\n",
    "                                        \"content\": {\"type\": \"string\", \"description\": \"Content of the section.\"},\n",
    "                                        \"subsections\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Nested subsections. Each must also be a complete SectionItem object. Provide an empty list if no subsections.\",\n",
    "                                            \"items\": {\"$ref\": \"#/properties/analysis/properties/identified_sections/items\"}\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"tag\", \"number\", \"title\", \"content\", \"subsections\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            },\n",
    "                            \"document_meta_found\": {\n",
    "                                \"type\": [\"object\", \"null\"],\n",
    "                                \"description\": \"Document metadata found in the chunk, or null if none found. If an object, all its fields must be provided (use null for optional text fields).\",\n",
    "                                \"properties\": {\n",
    "                                    \"document_type\": {\"type\": \"string\", \"description\": \"Type of the document.\"},\n",
    "                                    \"number\": {\"type\": [\"string\", \"null\"], \"description\": \"Document number. Null if not applicable.\"},\n",
    "                                    \"year\": {\"type\": [\"string\", \"null\"], \"description\": \"Year of the document. Null if not applicable.\"},\n",
    "                                    \"title\": {\"type\": [\"string\", \"null\"], \"description\": \"Title of the document. Null if not applicable.\"},\n",
    "                                    \"authority\": {\"type\": [\"string\", \"null\"], \"description\": \"Issuing authority. Null if not applicable.\"}\n",
    "                                },\n",
    "                                \"required\": [\"document_type\", \"number\", \"year\", \"title\", \"authority\"], # Required if object\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            \"confidence\": {\"type\": \"number\", \"description\": \"Confidence score of the analysis (0.0 to 1.0).\"},\n",
    "                            \"notes\": {\"type\": \"string\", \"description\": \"Any notes about the analysis. Can be an empty string.\"}\n",
    "                        },\n",
    "                        \"required\": [\"identified_sections\", \"document_meta_found\", \"confidence\", \"notes\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"chunk_data\", \"analysis\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"update_processing_status\",\n",
    "            \"description\": \"Update the processing status of a document (e.g., created, processing, completed, failed).\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the document.\"},\n",
    "                    \"status\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"created\", \"processing\", \"completed\", \"failed\"],\n",
    "                        \"description\": \"The new processing status.\"\n",
    "                    },\n",
    "                    \"total_chunks\": {\n",
    "                        \"type\": [\"integer\", \"null\"],\n",
    "                        \"description\": \"Total number of chunks for the document. Provide null if not updating or not known.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\", \"status\", \"total_chunks\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_MAPPING = {\n",
    "    \"create_document_in_db\": create_document_in_db,\n",
    "    \"get_document_from_db\": get_document_from_db,\n",
    "    \"get_context_for_chunk\": get_context_for_chunk,\n",
    "    \"update_document_section\": update_document_section,\n",
    "    \"add_document_section\": add_document_section,\n",
    "    \"store_chunk_analysis\": store_chunk_analysis,\n",
    "    \"update_processing_status\": update_processing_status\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function tools with proper Pydantic models\n",
    "async def create_document_in_db(document_id: str, meta: dict, source_file: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a new legal document in MongoDB\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        meta: Document metadata (type, number, year, title, authority)\n",
    "        source_file: Path to source file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert dict to Pydantic model\n",
    "        meta_model = DocumentMetaInput(**meta)\n",
    "        meta_dict = meta_model.model_dump()\n",
    "        \n",
    "        document = {\n",
    "            \"document_id\": document_id,\n",
    "            \"meta\": {\n",
    "                **meta_dict,\n",
    "                \"source_file\": source_file,\n",
    "                \"created_at\": datetime.datetime.now(datetime.UTC),\n",
    "                \"updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "            },\n",
    "            \"structure\": {\n",
    "                \"preface\": [],\n",
    "                \"preamble\": [],\n",
    "                \"body\": [],\n",
    "                \"conclusions\": []\n",
    "            },\n",
    "            \"processing_status\": {\n",
    "                \"total_chunks\": 0,\n",
    "                \"processed_chunks\": 0,\n",
    "                \"status\": \"created\",\n",
    "                \"last_updated\": datetime.datetime.now(datetime.UTC)\n",
    "            },\n",
    "            \"chunks\": []\n",
    "        }\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].insert_one(document)\n",
    "        return f\"Document created with ID: {result.inserted_id}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error creating document: {str(e)}\"\n",
    "\n",
    "async def get_document_from_db(document_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve a legal document from MongoDB\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document = await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": document_id}\n",
    "        )\n",
    "        \n",
    "        if document:\n",
    "            # Convert ObjectId to string for JSON serialization\n",
    "            document[\"_id\"] = str(document[\"_id\"])\n",
    "            return json.dumps(document, default=str, ensure_ascii=False, indent=2)\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving document: {str(e)}\"\n",
    "\n",
    "async def update_document_section(document_id: str, section_type: str, section_data: list) -> str:\n",
    "    \"\"\"\n",
    "    Update a specific section of a legal document (PUT operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        section_type: Type of section (preface, preamble, body, conclusions)\n",
    "        section_data: Section data to update\n",
    "    \"\"\"\n",
    "    try:\n",
    "        valid_sections = [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "        if section_type not in valid_sections:\n",
    "            return f\"Invalid section type. Must be one of: {valid_sections}\"\n",
    "        \n",
    "        # Convert list of dicts to Pydantic models\n",
    "        section_models = [SectionItem(**item) for item in section_data]\n",
    "        section_data_dict = [item.model_dump() for item in section_models]\n",
    "        \n",
    "        update_data = {\n",
    "            f\"structure.{section_type}\": section_data_dict,\n",
    "            \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\"$set\": update_data}\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Updated {section_type} section for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error updating document section: {str(e)}\"\n",
    "\n",
    "async def add_document_section(document_id: str, section_type: str, section_item: dict) -> str:\n",
    "    \"\"\"\n",
    "    Add a new item to a document section (POST operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        section_type: Type of section (preface, preamble, body, conclusions)\n",
    "        section_item: New section item to add\n",
    "    \"\"\"\n",
    "    try:\n",
    "        valid_sections = [\"preface\", \"preamble\", \"body\", \"conclusions\"]\n",
    "        if section_type not in valid_sections:\n",
    "            return f\"Invalid section type. Must be one of: {valid_sections}\"\n",
    "        \n",
    "        # Convert dict to Pydantic model\n",
    "        section_item_model = SectionItem(**section_item)\n",
    "        section_item_dict = section_item_model.model_dump()\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\n",
    "                \"$push\": {f\"structure.{section_type}\": section_item_dict}, # Push only the section item\n",
    "                \"$set\": {\"meta.updated_at\": datetime.datetime.now(datetime.UTC)}  # Set the timestamp\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Added new item to {section_type} section for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error adding to document section: {str(e)}\"\n",
    "\n",
    "async def store_chunk_analysis(document_id: str, chunk_data: dict, analysis: dict) -> str:\n",
    "    \"\"\"\n",
    "    Store chunk analysis results in the document (PATCH operation)\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        chunk_data: Chunk information (chunk_id, start_pos, end_pos, content)\n",
    "        analysis: Analysis results from the agent\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert dicts to Pydantic models\n",
    "        chunk_data_model = ChunkData(**chunk_data)\n",
    "        analysis_model = AnalysisResult(**analysis)\n",
    "        \n",
    "        # Convert Pydantic models to dicts\n",
    "        chunk_data_dict = chunk_data_model.model_dump()\n",
    "        analysis_dict = analysis_model.model_dump()\n",
    "        \n",
    "        chunk_with_analysis = {\n",
    "            **chunk_data_dict,\n",
    "            \"analysis\": analysis_dict,\n",
    "            \"processed_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        # Add chunk to document\n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\n",
    "                \"$push\": {\"chunks\": chunk_with_analysis},\n",
    "                \"$inc\": {\"processing_status.processed_chunks\": 1},\n",
    "                \"$set\": {\n",
    "                    \"processing_status.last_updated\": datetime.datetime.now(datetime.UTC),\n",
    "                    \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Stored analysis for chunk {chunk_data_model.chunk_id} in document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error storing chunk analysis: {str(e)}\"\n",
    "\n",
    "async def update_processing_status(document_id: str, status: str, total_chunks: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Update document processing status\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        status: New status (created, processing, completed, failed)\n",
    "        total_chunks: Total number of chunks (optional)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        update_data = {\n",
    "            \"processing_status.status\": status,\n",
    "            \"processing_status.last_updated\": datetime.datetime.now(datetime.UTC),\n",
    "            \"meta.updated_at\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        \n",
    "        if total_chunks is not None:\n",
    "            update_data[\"processing_status.total_chunks\"] = total_chunks\n",
    "        \n",
    "        result = await mongo_manager.db[COLLECTIONS[\"documents\"]].update_one(\n",
    "            {\"document_id\": document_id},\n",
    "            {\"$set\": update_data}\n",
    "        )\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            return f\"Updated processing status to '{status}' for document {document_id}\"\n",
    "        else:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error updating processing status: {str(e)}\"\n",
    "    \n",
    "async def get_context_for_chunk(document_id: str, current_chunk_id: str, context_window_size: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Fetch context from previously processed chunks\n",
    "    \n",
    "    Args:\n",
    "        document_id: Unique identifier for the document\n",
    "        current_chunk_id: ID of the current chunk being processed\n",
    "        context_window_size: Number of previous chunks to include in context\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the document\n",
    "        document = await mongo_manager.db[COLLECTIONS[\"documents\"]].find_one(\n",
    "            {\"document_id\": document_id}\n",
    "        )\n",
    "        \n",
    "        if not document:\n",
    "            return f\"Document not found: {document_id}\"\n",
    "        \n",
    "        # Extract current chunk number\n",
    "        try:\n",
    "            current_chunk_num = int(current_chunk_id.split('_')[-1])\n",
    "        except:\n",
    "            return \"Invalid chunk ID format\"\n",
    "        \n",
    "        # Find previous chunks\n",
    "        previous_chunks = []\n",
    "        for chunk in document.get(\"chunks\", []):\n",
    "            try:\n",
    "                chunk_num = int(chunk[\"chunk_id\"].split('_')[-1])\n",
    "                if chunk_num < current_chunk_num and chunk_num >= current_chunk_num - context_window_size:\n",
    "                    previous_chunks.append(chunk)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Sort by chunk number\n",
    "        previous_chunks.sort(key=lambda x: int(x[\"chunk_id\"].split('_')[-1]))\n",
    "        \n",
    "        # Format context information\n",
    "        context = {\n",
    "            \"previous_chunks\": previous_chunks,\n",
    "            \"document_structure\": document.get(\"structure\", {}),\n",
    "            \"metadata\": document.get(\"meta\", {})\n",
    "        }\n",
    "        \n",
    "        return json.dumps(context, default=str, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error fetching context: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkAnalysis(BaseModel):\n",
    "    chunk_id: str\n",
    "    identified_sections: List[DocumentSection]\n",
    "    document_meta_found: Optional[DocumentMeta] = None\n",
    "    confidence: float  # 0.0 to 1.0\n",
    "    notes: str = \"\"\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"ChunkAnalysis\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": AnalysisResult.model_json_schema()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agentic_loop(system_prompt: str, prompt: str, tools, tool_mapping, response_format=None):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        response = await client.chat.completions.create(\n",
    "            # model=\"openai/gpt-4.1-mini\",\n",
    "            model=\"google/gemini-2.5-flash-preview-05-20\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            response_format=response_format\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message\n",
    "        # messages.append(message.dict()) # deprecated\n",
    "        messages.append(message.model_dump())\n",
    "\n",
    "        if message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "                tool_result = await tool_mapping[tool_name](**tool_args)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": json.dumps(tool_result)\n",
    "                })\n",
    "        else:\n",
    "            return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available legal document tags/elements\n",
    "AVAILABLE_TAGS = {\n",
    "    \"structural\": [\"bab\", \"bagian\", \"paragraf\", \"pasal\", \"ayat\"],\n",
    "    \"preamble\": [\"konsideran_menimbang\", \"konsideran_mengingat\", \"memutuskan\"],\n",
    "    \"content\": [\"definisi\", \"ketentuan_umum\", \"ketentuan_khusus\", \"sanksi\", \"ketentuan_peralihan\", \"ketentuan_penutup\"],\n",
    "    \"meta\": [\"judul\", \"nomor\", \"tahun\", \"tentang\", \"pembentuk\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the document analysis agent\n",
    "system_prompt=f\"\"\"\n",
    "You are an expert in Indonesian legal documents with access to a MongoDB database.\n",
    "Your task is to analyze chunks of legal text with awareness of previously processed chunks.\n",
    "\n",
    "Available tags you can use:\n",
    "{json.dumps(AVAILABLE_TAGS, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Your workflow:\n",
    "1. Decide if you need context from previous chunks\n",
    "2. If needed, fetch context using get_context_for_chunk\n",
    "3. Analyze the current chunk with awareness of this context\n",
    "4. Store your analysis and update the document structure\n",
    "5. Consider how this chunk connects to previous chunks\n",
    "\n",
    "When analyzing with context:\n",
    "- Look for sections that span across chunk boundaries\n",
    "- Avoid duplicating sections already identified in previous chunks\n",
    "- Connect partial sections across chunks (e.g., if a pasal starts in one chunk and continues in another)\n",
    "- Use document structure information to maintain consistency\n",
    "\n",
    "Available MongoDB tools:\n",
    "- create_document_in_db: Create a new document\n",
    "- get_document_from_db: Retrieve existing document\n",
    "- get_context_for_chunk: Fetch context from previous chunks\n",
    "- update_document_section: Update entire sections (PUT)\n",
    "- add_document_section: Add items to sections (POST)\n",
    "- store_chunk_analysis: Store chunk analysis results\n",
    "- update_processing_status: Update processing status\n",
    "\n",
    "Rules:\n",
    "- Always consider context before making decisions\n",
    "- Be conservative when deciding what's a new section vs. continuation\n",
    "- Store your analysis even if you're uncertain\n",
    "- Add notes about cross-chunk connections\n",
    "\n",
    "Tips:\n",
    "- You should check if the db exists and if the document is already in the db\n",
    "- If the document is not in the db, create it with the initial metadata\n",
    "- Use the get_context_for_chunk tool to fetch context from previous chunks\n",
    "- Use the store_chunk_analysis tool to save your analysis results\n",
    "- Use the update_document_section tool to update sections\n",
    "- Use the add_document_section tool to add new items to sections\n",
    "- Use the update_processing_status tool to update the processing status of the document\n",
    "- If you need to create a new document, use the create_document_in_db tool \n",
    "- If you need to retrieve a document, use the get_document_from_db tool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing chunk: chunk_001\n",
      "Content preview: PRESIDEN\n",
      "REPUBLIK INDONESIA\n",
      "UNDANG-UNDANG REPUBLIK INDONESIA\n",
      "NOMOR 8 TAHUN 1961\n",
      "TENTANG\n",
      "WAJIB KERJA SARJANA\n",
      "PRESIDEN REPUBLIK INDONESIA,\n",
      "Menimbang:a.bahwa ilmu dan keahlian azasnya untuk mengabdi kepa...\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if 'chunks' in locals() and len(chunks) > 0:\n",
    "    first_chunk = chunks[0]\n",
    "    \n",
    "    print(f\"Analyzing chunk: {first_chunk['chunk_id']}\")\n",
    "    print(f\"Content preview: {first_chunk['content'][:200]}...\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    prompt = f\"Analyze this chunk of Indonesian legal document text:\\n\\nChunk ID: {first_chunk['chunk_id']}\\n\\nContent:\\n{first_chunk['content']}. Add/update document section based on this chunk. Move on to the next chunk if you're finished. Do it until you're finished with all the chunks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB: hukum_terbuka\n"
     ]
    }
   ],
   "source": [
    "# result_json = await run_agentic_loop(prompt, tools, TOOL_MAPPING, response_format)\n",
    "# analysis = AnalysisResult.model_validate_json(result_json)\n",
    "\n",
    "await mongo_manager.connect() \n",
    "\n",
    "result_json = await run_agentic_loop(system_prompt, prompt, tools, TOOL_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The analysis for `chunk_001` has been successfully stored after creating the document.\\n\\nHere\\'s my analysis of the chunk:\\n\\n**Document Metadata:**\\n*   **Document Type:** UNDANG-UNDANG\\n*   **Number:** 8\\n*   **Year:** 1961\\n*   **Tentang (About):** WAJIB KERJA SARJANA\\n*   **Pembentuk (Forming Authority):** PRESIDEN REPUBLIK INDONESIA\\n\\n**Identified Sections:**\\n\\n*   **Preamble - Menimbang (Considering):**\\n    *   **Tag:** `konsideran_menimbang`\\n    *   **Content:** Contains reasons for the law, starting with \"a.bahwa ilmu dan keahlian azasnya...\"\\n*   **Preamble - Mengingat (Recalling):**\\n    *   **Tag:** `konsideran_mengingat`\\n    *   **Content:** Lists legal bases, starting with \"a.Pasal 5 ayat (1) jo. pasal 20 ayat (1)...\"\\n*   **Preamble - MEMUTUSKAN (DECIDES):**\\n    *   **Tag:** `memutuskan`\\n    *   **Content:** Details decisions made, including revocation and establishment, starting with \"I. Mencabut:Undang-undang Nomor 8 tahun 1951...\"\\n*   **Structural - Pasal 1:**\\n    *   **Tag:** `pasal`\\n    *   **Number:** 1\\n    *   **Content:** (empty, as the content is immediately broken down into ayat)\\n    *   **Subsections (Ayat):**\\n        *   **Ayat (1):**\\n            *   **Tag:** `ayat`\\n            *   **Number:** (1)\\n            *   **Content:** \"Tiap warganegara, baik pria maupun wanita, a.yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi Negara; b.yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi Swasta, yang ditunjuk oleh Menteri yang diserahi urusan Perguruan tinggi, c.yang memperoleh ijazah ujian penghabisan pada Perguruan Tinggi diluar negeri, yang ditunjuk oleh Menteri yang diserahi urusan perguruan tinggi. Semuanya itu disebut sarjana, wajib bekerja pada Pemerintah atau pada perusahaan-perusahaan yang ditunjuk oleh Pemerintah sekurang-kurangnya selama tiga tahun berturut-turut .\"\\n        *   **Ayat (2):**\\n            *   **Tag:** `ayat`\\n            *   **Number:** (2)\\n            *   **Content:** \"Dalam peraturan ini Akademi dikecualikan dari istilah Perguruan Tinggi.\"\\n        *   **Ayat (3):**\\n            *   **Tag:** `ayat`\\n            *   **Number:** (3)\\n            *   **Content:** \"Bagi pendidikan tinggi Kedokteran, Kedokteran gigi, KedokteranHewan, Apoteker dan Akuntan ijazah ujian penghab\" (This ayat is incomplete and will likely continue in the next chunk).\\n\\n**Next Steps:**\\n\\n*   Since `Pasal 1 Ayat (3)` is incomplete, the next chunk will likely contain its continuation. I will need to use `get_context_for_chunk` in the next processing step to ensure I properly append to or complete this section.\\n*   I expect the subsequent chunks to continue with more `pasal` and `ayat` sections, or potentially new structural sections like `bab`, `bagian`, or `paragraf`.'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
